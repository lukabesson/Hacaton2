{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bfc49f5-cd63-49ef-8886-b278c0462040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c72cd66-aa3f-44b9-8af3-b878e7186a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>age</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>monthly_inhand_salary</th>\n",
       "      <th>num_bank_accounts</th>\n",
       "      <th>num_credit_card</th>\n",
       "      <th>num_of_loan</th>\n",
       "      <th>num_credit_inquiries</th>\n",
       "      <th>credit_history_age</th>\n",
       "      <th>amount_invested_monthly</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation_Musician</th>\n",
       "      <th>occupation_Scientist</th>\n",
       "      <th>occupation_Teacher</th>\n",
       "      <th>occupation_Writer</th>\n",
       "      <th>payment_behaviour_High_spent_Large_value_payments</th>\n",
       "      <th>payment_behaviour_High_spent_Medium_value_payments</th>\n",
       "      <th>payment_behaviour_High_spent_Small_value_payments</th>\n",
       "      <th>payment_behaviour_Low_spent_Large_value_payments</th>\n",
       "      <th>payment_behaviour_Low_spent_Medium_value_payments</th>\n",
       "      <th>payment_behaviour_Low_spent_Small_value_payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>21.46538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>21.46538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>21.46538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>21.46538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>21.46538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month   age  annual_income  monthly_inhand_salary  num_bank_accounts  \\\n",
       "0      1  23.0       19114.12            1824.843333                3.0   \n",
       "1      2  23.0       19114.12            1824.843333                3.0   \n",
       "2      3  23.0       19114.12            1824.843333                3.0   \n",
       "3      4  23.0       19114.12            1824.843333                3.0   \n",
       "4      5  23.0       19114.12            1824.843333                3.0   \n",
       "\n",
       "   num_credit_card  num_of_loan  num_credit_inquiries  credit_history_age  \\\n",
       "0              4.0          4.0                   4.0               265.0   \n",
       "1              4.0          4.0                   4.0               266.0   \n",
       "2              4.0          4.0                   4.0               267.0   \n",
       "3              4.0          4.0                   4.0               268.0   \n",
       "4              4.0          4.0                   4.0               269.0   \n",
       "\n",
       "   amount_invested_monthly  ...  occupation_Musician  occupation_Scientist  \\\n",
       "0                 21.46538  ...                  0.0                   1.0   \n",
       "1                 21.46538  ...                  0.0                   1.0   \n",
       "2                 21.46538  ...                  0.0                   1.0   \n",
       "3                 21.46538  ...                  0.0                   1.0   \n",
       "4                 21.46538  ...                  0.0                   1.0   \n",
       "\n",
       "   occupation_Teacher  occupation_Writer  \\\n",
       "0                 0.0                0.0   \n",
       "1                 0.0                0.0   \n",
       "2                 0.0                0.0   \n",
       "3                 0.0                0.0   \n",
       "4                 0.0                0.0   \n",
       "\n",
       "   payment_behaviour_High_spent_Large_value_payments  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "\n",
       "   payment_behaviour_High_spent_Medium_value_payments  \\\n",
       "0                                                0.0    \n",
       "1                                                0.0    \n",
       "2                                                0.0    \n",
       "3                                                0.0    \n",
       "4                                                1.0    \n",
       "\n",
       "   payment_behaviour_High_spent_Small_value_payments  \\\n",
       "0                                                1.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "\n",
       "   payment_behaviour_Low_spent_Large_value_payments  \\\n",
       "0                                               0.0   \n",
       "1                                               1.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   payment_behaviour_Low_spent_Medium_value_payments  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                1.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "\n",
       "   payment_behaviour_Low_spent_Small_value_payments  \n",
       "0                                               0.0  \n",
       "1                                               0.0  \n",
       "2                                               0.0  \n",
       "3                                               1.0  \n",
       "4                                               0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('credit_score_ds_1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "401f4a7e-9680-4845-ae5a-6e51bbe9c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Определение нейронной сети\n",
    "class MoreComplexClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4, output_size):\n",
    "        super(MoreComplexClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.layer4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.layer5 = nn.Linear(hidden_size4, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5cd03519-c5b0-42ae-a623-10102074484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x = df.drop(['month', 'credit_score'], axis=1)\n",
    "y = np.array(df['credit_score'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "t_x = scaler.transform(x)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(t_x, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2d442fd-856b-486a-933b-f9f8a3fdd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование данных в тензоры PyTorch\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a8a6446-3e5c-4a5d-93aa-8bddc75e1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем параметры\n",
    "input_size = 31  # Размерность входных данных\n",
    "hidden_size1 = 200  # Количество нейронов в первом скрытом слое\n",
    "hidden_size2 = 200  # Количество нейронов во втором скрытом слое\n",
    "hidden_size3 = 100\n",
    "hidden_size4 = 50\n",
    "output_size = 1  # Количество выходных нейронов (бинарная классификация)\n",
    "\n",
    "# Создаем экземпляр модели\n",
    "model = MoreComplexClassifier(input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4, output_size)\n",
    "\n",
    "# Определяем функцию потерь и оптимизатор\n",
    "criterion = nn.BCELoss()  # Бинарная кросс-энтропия для бинарной классификации\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "754d78c4-c937-477e-be42-357bf1b2d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Loss: 0.5775\n",
      "Epoch [20/500], Loss: 0.5183\n",
      "Epoch [30/500], Loss: 0.4966\n",
      "Epoch [40/500], Loss: 0.4878\n",
      "Epoch [50/500], Loss: 0.4818\n",
      "Epoch [60/500], Loss: 0.4783\n",
      "Epoch [70/500], Loss: 0.4773\n",
      "Epoch [80/500], Loss: 0.4749\n",
      "Epoch [90/500], Loss: 0.4730\n",
      "Epoch [100/500], Loss: 0.4749\n",
      "Epoch [110/500], Loss: 0.4693\n",
      "Epoch [120/500], Loss: 0.4668\n",
      "Epoch [130/500], Loss: 0.4753\n",
      "Epoch [140/500], Loss: 0.4686\n",
      "Epoch [150/500], Loss: 0.4639\n",
      "Epoch [160/500], Loss: 0.4651\n",
      "Epoch [170/500], Loss: 0.4626\n",
      "Epoch [180/500], Loss: 0.4640\n",
      "Epoch [190/500], Loss: 0.4631\n",
      "Epoch [200/500], Loss: 0.4713\n",
      "Epoch [210/500], Loss: 0.4627\n",
      "Epoch [220/500], Loss: 0.4617\n",
      "Epoch [230/500], Loss: 0.4598\n",
      "Epoch [240/500], Loss: 0.4585\n",
      "Epoch [250/500], Loss: 0.4641\n",
      "Epoch [260/500], Loss: 0.4583\n",
      "Epoch [270/500], Loss: 0.4631\n",
      "Epoch [280/500], Loss: 0.4592\n",
      "Epoch [290/500], Loss: 0.4551\n",
      "Epoch [300/500], Loss: 0.4625\n",
      "Epoch [310/500], Loss: 0.4556\n",
      "Epoch [320/500], Loss: 0.4524\n",
      "Epoch [330/500], Loss: 0.4620\n",
      "Epoch [340/500], Loss: 0.4570\n",
      "Epoch [350/500], Loss: 0.4550\n",
      "Epoch [360/500], Loss: 0.4524\n",
      "Epoch [370/500], Loss: 0.4514\n",
      "Epoch [380/500], Loss: 0.4558\n",
      "Epoch [390/500], Loss: 0.4526\n",
      "Epoch [400/500], Loss: 0.4495\n",
      "Epoch [410/500], Loss: 0.4540\n",
      "Epoch [420/500], Loss: 0.4489\n",
      "Epoch [430/500], Loss: 0.4502\n",
      "Epoch [440/500], Loss: 0.4446\n",
      "Epoch [450/500], Loss: 0.4812\n",
      "Epoch [460/500], Loss: 0.4674\n",
      "Epoch [470/500], Loss: 0.4619\n",
      "Epoch [480/500], Loss: 0.4569\n",
      "Epoch [490/500], Loss: 0.4540\n",
      "Epoch [500/500], Loss: 0.4528\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Обучение модели\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    # Прямой проход\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))\n",
    "\n",
    "    # Обратный проход и оптимизация\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Выводим значение функции потерь на каждой эпохе\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2bc7bc37-2880-4f9e-9324-69a0f644630b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC на тренировочном наборе: 0.8253\n",
      "AUC на тестовом наборе: 0.8175\n"
     ]
    }
   ],
   "source": [
    "# Оценка точности с использованием AUC на тестовом наборе\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_probs_test = model(X_test)\n",
    "    y_pred_probs_train = model(X_train)\n",
    "    y_pred_probs_test = y_pred_probs_test.numpy().flatten()\n",
    "    y_pred_probs_train = y_pred_probs_train.numpy().flatten()\n",
    "    auc_score_test = roc_auc_score(y_test.numpy(), y_pred_probs_test)\n",
    "    auc_score_train = roc_auc_score(y_train.numpy(), y_pred_probs_train)\n",
    "    \n",
    "print(f'AUC на тренировочном наборе: {auc_score_train:.4f}')\n",
    "print(f'AUC на тестовом наборе: {auc_score_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bec9983-d5fc-4b9a-8d90-b2eb61b48f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 31  # Размерность входных данных\n",
    "hidden_size1 = 100  # Количество нейронов в первом скрытом слое\n",
    "hidden_size2 = 100  # Количество нейронов во втором скрытом слое\n",
    "hidden_size3 = 50\n",
    "output_size = 1  # Количество выходных нейронов (бинарная классификация)\n",
    "\n",
    "\n",
    "AUC на тренировочном наборе: 0.8251\n",
    "AUC на тестовом наборе: 0.8169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4d007e65-446d-4ba0-92f2-55398bd0f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes1 = [i for i in np.arange(5, 301, 10)]\n",
    "hidden_layer_sizes2 = [i for i in np.arange(5, 301, 10)]\n",
    "hidden_layer_sizes3 = [i for i in np.arange(5, 301, 10)]\n",
    "hidden_layer_sizes4 = [i for i in np.arange(5, 301, 10)]\n",
    "num_epochs_list = [i for i in np.arange(50, 1000, 50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5ead1a2a-1eb2-4a5d-8ece-96309e8b1fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/50], Loss: 0.6770\n",
      "Epoch [500/100], Loss: 0.6359\n",
      "Epoch [500/150], Loss: 0.5973\n",
      "Epoch [500/200], Loss: 0.6240\n",
      "Epoch [500/250], Loss: 0.5820\n",
      "Epoch [500/300], Loss: 0.5901\n",
      "Epoch [500/350], Loss: 0.5881\n",
      "Epoch [500/400], Loss: 0.5713\n",
      "Epoch [500/450], Loss: 0.5492\n",
      "Epoch [500/500], Loss: 0.5502\n",
      "Epoch [500/550], Loss: 0.5364\n",
      "Epoch [500/600], Loss: 0.5242\n",
      "Epoch [500/650], Loss: 0.5294\n",
      "Epoch [500/700], Loss: 0.5242\n",
      "Epoch [500/750], Loss: 0.5165\n",
      "Epoch [500/800], Loss: 0.5218\n",
      "Epoch [500/850], Loss: 0.5164\n",
      "Epoch [500/900], Loss: 0.5117\n",
      "Epoch [500/950], Loss: 0.5138\n",
      "Epoch [500/50], Loss: 0.5093\n",
      "Epoch [500/100], Loss: 0.5054\n",
      "Epoch [500/150], Loss: 0.5072\n",
      "Epoch [500/200], Loss: 0.5024\n",
      "Epoch [500/250], Loss: 0.5033\n",
      "Epoch [500/300], Loss: 0.4992\n",
      "Epoch [500/350], Loss: 0.4963\n",
      "Epoch [500/400], Loss: 0.4955\n",
      "Epoch [500/450], Loss: 0.4936\n",
      "Epoch [500/500], Loss: 0.4950\n",
      "Epoch [500/550], Loss: 0.4930\n",
      "Epoch [500/600], Loss: 0.4933\n",
      "Epoch [500/650], Loss: 0.4915\n",
      "Epoch [500/700], Loss: 0.4918\n",
      "Epoch [500/750], Loss: 0.4902\n",
      "Epoch [500/800], Loss: 0.4897\n",
      "Epoch [500/850], Loss: 0.4887\n",
      "Epoch [500/900], Loss: 0.4889\n",
      "Epoch [500/950], Loss: 0.4878\n",
      "Epoch [500/50], Loss: 0.4878\n",
      "Epoch [500/100], Loss: 0.4866\n",
      "Epoch [500/150], Loss: 0.4866\n",
      "Epoch [500/200], Loss: 0.4859\n",
      "Epoch [500/250], Loss: 0.4850\n",
      "Epoch [500/300], Loss: 0.4852\n",
      "Epoch [500/350], Loss: 0.4844\n",
      "Epoch [500/400], Loss: 0.4836\n",
      "Epoch [500/450], Loss: 0.4835\n",
      "Epoch [500/500], Loss: 0.4830\n",
      "Epoch [500/550], Loss: 0.4822\n",
      "Epoch [500/600], Loss: 0.4819\n",
      "Epoch [500/650], Loss: 0.4817\n",
      "Epoch [500/700], Loss: 0.4815\n",
      "Epoch [500/750], Loss: 0.4810\n",
      "Epoch [500/800], Loss: 0.4805\n",
      "Epoch [500/850], Loss: 0.4799\n",
      "Epoch [500/900], Loss: 0.4795\n",
      "Epoch [500/950], Loss: 0.4789\n",
      "Epoch [500/50], Loss: 0.4788\n",
      "Epoch [500/100], Loss: 0.4791\n",
      "Epoch [500/150], Loss: 0.4808\n",
      "Epoch [500/200], Loss: 0.4822\n",
      "Epoch [500/250], Loss: 0.4799\n",
      "Epoch [500/300], Loss: 0.4769\n",
      "Epoch [500/350], Loss: 0.4796\n",
      "Epoch [500/400], Loss: 0.4784\n",
      "Epoch [500/450], Loss: 0.4766\n",
      "Epoch [500/500], Loss: 0.4788\n",
      "Epoch [500/550], Loss: 0.4769\n",
      "Epoch [500/600], Loss: 0.4761\n",
      "Epoch [500/650], Loss: 0.4779\n",
      "Epoch [500/700], Loss: 0.4762\n",
      "Epoch [500/750], Loss: 0.4753\n",
      "Epoch [500/800], Loss: 0.4768\n",
      "Epoch [500/850], Loss: 0.4755\n",
      "Epoch [500/900], Loss: 0.4747\n",
      "Epoch [500/950], Loss: 0.4758\n",
      "Epoch [500/50], Loss: 0.4749\n",
      "Epoch [500/100], Loss: 0.4736\n",
      "Epoch [500/150], Loss: 0.4745\n",
      "Epoch [500/200], Loss: 0.4752\n",
      "Epoch [500/250], Loss: 0.4737\n",
      "Epoch [500/300], Loss: 0.4720\n",
      "Epoch [500/350], Loss: 0.4717\n",
      "Epoch [500/400], Loss: 0.4727\n",
      "Epoch [500/450], Loss: 0.4778\n",
      "Epoch [500/500], Loss: 0.4797\n",
      "Epoch [500/550], Loss: 0.4747\n",
      "Epoch [500/600], Loss: 0.4710\n",
      "Epoch [500/650], Loss: 0.4747\n",
      "Epoch [500/700], Loss: 0.4728\n",
      "Epoch [500/750], Loss: 0.4707\n",
      "Epoch [500/800], Loss: 0.4737\n",
      "Epoch [500/850], Loss: 0.4703\n",
      "Epoch [500/900], Loss: 0.4702\n",
      "Epoch [500/950], Loss: 0.4722\n",
      "Epoch [500/50], Loss: 0.4692\n",
      "Epoch [500/100], Loss: 0.4690\n",
      "Epoch [500/150], Loss: 0.4703\n",
      "Epoch [500/200], Loss: 0.4705\n",
      "Epoch [500/250], Loss: 0.4682\n",
      "Epoch [500/300], Loss: 0.4680\n",
      "Epoch [500/350], Loss: 0.4688\n",
      "Epoch [500/400], Loss: 0.4691\n",
      "Epoch [500/450], Loss: 0.4680\n",
      "Epoch [500/500], Loss: 0.4671\n",
      "Epoch [500/550], Loss: 0.4673\n",
      "Epoch [500/600], Loss: 0.4678\n",
      "Epoch [500/650], Loss: 0.4687\n",
      "Epoch [500/700], Loss: 0.4684\n",
      "Epoch [500/750], Loss: 0.4683\n",
      "Epoch [500/800], Loss: 0.4674\n",
      "Epoch [500/850], Loss: 0.4665\n",
      "Epoch [500/900], Loss: 0.4659\n",
      "Epoch [500/950], Loss: 0.4661\n",
      "Epoch [500/50], Loss: 0.4668\n",
      "Epoch [500/100], Loss: 0.4688\n",
      "Epoch [500/150], Loss: 0.4741\n",
      "Epoch [500/200], Loss: 0.4797\n",
      "Epoch [500/250], Loss: 0.4768\n",
      "Epoch [500/300], Loss: 0.4673\n",
      "Epoch [500/350], Loss: 0.4759\n",
      "Epoch [500/400], Loss: 0.4686\n",
      "Epoch [500/450], Loss: 0.4730\n",
      "Epoch [500/500], Loss: 0.4689\n",
      "Epoch [500/550], Loss: 0.4703\n",
      "Epoch [500/600], Loss: 0.4698\n",
      "Epoch [500/650], Loss: 0.4673\n",
      "Epoch [500/700], Loss: 0.4708\n",
      "Epoch [500/750], Loss: 0.4666\n",
      "Epoch [500/800], Loss: 0.4679\n",
      "Epoch [500/850], Loss: 0.4687\n",
      "Epoch [500/900], Loss: 0.4658\n",
      "Epoch [500/950], Loss: 0.4678\n",
      "Epoch [500/50], Loss: 0.4668\n",
      "Epoch [500/100], Loss: 0.4657\n",
      "Epoch [500/150], Loss: 0.4673\n",
      "Epoch [500/200], Loss: 0.4659\n",
      "Epoch [500/250], Loss: 0.4653\n",
      "Epoch [500/300], Loss: 0.4665\n",
      "Epoch [500/350], Loss: 0.4656\n",
      "Epoch [500/400], Loss: 0.4648\n",
      "Epoch [500/450], Loss: 0.4655\n",
      "Epoch [500/500], Loss: 0.4654\n",
      "Epoch [500/550], Loss: 0.4645\n",
      "Epoch [500/600], Loss: 0.4644\n",
      "Epoch [500/650], Loss: 0.4649\n",
      "Epoch [500/700], Loss: 0.4650\n",
      "Epoch [500/750], Loss: 0.4644\n",
      "Epoch [500/800], Loss: 0.4638\n",
      "Epoch [500/850], Loss: 0.4635\n",
      "Epoch [500/900], Loss: 0.4637\n",
      "Epoch [500/950], Loss: 0.4644\n",
      "Epoch [500/50], Loss: 0.4658\n",
      "Epoch [500/100], Loss: 0.4689\n",
      "Epoch [500/150], Loss: 0.4723\n",
      "Epoch [500/200], Loss: 0.4714\n",
      "Epoch [500/250], Loss: 0.4647\n",
      "Epoch [500/300], Loss: 0.4667\n",
      "Epoch [500/350], Loss: 0.4688\n",
      "Epoch [500/400], Loss: 0.4641\n",
      "Epoch [500/450], Loss: 0.4661\n",
      "Epoch [500/500], Loss: 0.4682\n",
      "Epoch [500/550], Loss: 0.4643\n",
      "Epoch [500/600], Loss: 0.4641\n",
      "Epoch [500/650], Loss: 0.4670\n",
      "Epoch [500/700], Loss: 0.4657\n",
      "Epoch [500/750], Loss: 0.4631\n",
      "Epoch [500/800], Loss: 0.4639\n",
      "Epoch [500/850], Loss: 0.4655\n",
      "Epoch [500/900], Loss: 0.4649\n",
      "Epoch [500/950], Loss: 0.4630\n",
      "Epoch [500/50], Loss: 0.4626\n",
      "Epoch [500/100], Loss: 0.4637\n",
      "Epoch [500/150], Loss: 0.4645\n",
      "Epoch [500/200], Loss: 0.4641\n",
      "Epoch [500/250], Loss: 0.4627\n",
      "Epoch [500/300], Loss: 0.4619\n",
      "Epoch [500/350], Loss: 0.4624\n",
      "Epoch [500/400], Loss: 0.4635\n",
      "Epoch [500/450], Loss: 0.4651\n",
      "Epoch [500/500], Loss: 0.4666\n",
      "Epoch [500/550], Loss: 0.4671\n",
      "Epoch [500/600], Loss: 0.4643\n",
      "Epoch [500/650], Loss: 0.4617\n",
      "Epoch [500/700], Loss: 0.4628\n",
      "Epoch [500/750], Loss: 0.4663\n",
      "Epoch [500/800], Loss: 0.4716\n",
      "Epoch [500/850], Loss: 0.4704\n",
      "Epoch [500/900], Loss: 0.4633\n",
      "Epoch [500/950], Loss: 0.4640\n",
      "Epoch [500/50], Loss: 0.4671\n",
      "Epoch [500/100], Loss: 0.4629\n",
      "Epoch [500/150], Loss: 0.4630\n",
      "Epoch [500/200], Loss: 0.4660\n",
      "Epoch [500/250], Loss: 0.4637\n",
      "Epoch [500/300], Loss: 0.4616\n",
      "Epoch [500/350], Loss: 0.4640\n",
      "Epoch [500/400], Loss: 0.4651\n",
      "Epoch [500/450], Loss: 0.4621\n",
      "Epoch [500/500], Loss: 0.4612\n",
      "Epoch [500/550], Loss: 0.4631\n",
      "Epoch [500/600], Loss: 0.4630\n",
      "Epoch [500/650], Loss: 0.4611\n",
      "Epoch [500/700], Loss: 0.4605\n",
      "Epoch [500/750], Loss: 0.4615\n",
      "Epoch [500/800], Loss: 0.4628\n",
      "Epoch [500/850], Loss: 0.4627\n",
      "Epoch [500/900], Loss: 0.4616\n",
      "Epoch [500/950], Loss: 0.4601\n",
      "Epoch [500/50], Loss: 0.4600\n",
      "Epoch [500/100], Loss: 0.4612\n",
      "Epoch [500/150], Loss: 0.4634\n",
      "Epoch [500/200], Loss: 0.4683\n",
      "Epoch [500/250], Loss: 0.4715\n",
      "Epoch [500/300], Loss: 0.4677\n",
      "Epoch [500/350], Loss: 0.4609\n",
      "Epoch [500/400], Loss: 0.4663\n",
      "Epoch [500/450], Loss: 0.4655\n",
      "Epoch [500/500], Loss: 0.4605\n",
      "Epoch [500/550], Loss: 0.4646\n",
      "Epoch [500/600], Loss: 0.4655\n",
      "Epoch [500/650], Loss: 0.4604\n",
      "Epoch [500/700], Loss: 0.4621\n",
      "Epoch [500/750], Loss: 0.4653\n",
      "Epoch [500/800], Loss: 0.4618\n",
      "Epoch [500/850], Loss: 0.4599\n",
      "Epoch [500/900], Loss: 0.4624\n",
      "Epoch [500/950], Loss: 0.4622\n",
      "Epoch [500/50], Loss: 0.4598\n",
      "Epoch [500/100], Loss: 0.4596\n",
      "Epoch [500/150], Loss: 0.4613\n",
      "Epoch [500/200], Loss: 0.4618\n",
      "Epoch [500/250], Loss: 0.4600\n",
      "Epoch [500/300], Loss: 0.4587\n",
      "Epoch [500/350], Loss: 0.4593\n",
      "Epoch [500/400], Loss: 0.4607\n",
      "Epoch [500/450], Loss: 0.4624\n",
      "Epoch [500/500], Loss: 0.4635\n",
      "Epoch [500/550], Loss: 0.4633\n",
      "Epoch [500/600], Loss: 0.4598\n",
      "Epoch [500/650], Loss: 0.4583\n",
      "Epoch [500/700], Loss: 0.4607\n",
      "Epoch [500/750], Loss: 0.4640\n",
      "Epoch [500/800], Loss: 0.4655\n",
      "Epoch [500/850], Loss: 0.4618\n",
      "Epoch [500/900], Loss: 0.4582\n",
      "Epoch [500/950], Loss: 0.4593\n",
      "Epoch [500/50], Loss: 0.4619\n",
      "Epoch [500/100], Loss: 0.4616\n",
      "Epoch [500/150], Loss: 0.4587\n",
      "Epoch [500/200], Loss: 0.4575\n",
      "Epoch [500/250], Loss: 0.4585\n",
      "Epoch [500/300], Loss: 0.4601\n",
      "Epoch [500/350], Loss: 0.4615\n",
      "Epoch [500/400], Loss: 0.4606\n",
      "Epoch [500/450], Loss: 0.4589\n",
      "Epoch [500/500], Loss: 0.4570\n",
      "Epoch [500/550], Loss: 0.4568\n",
      "Epoch [500/600], Loss: 0.4583\n",
      "Epoch [500/650], Loss: 0.4606\n",
      "Epoch [500/700], Loss: 0.4650\n",
      "Epoch [500/750], Loss: 0.4668\n",
      "Epoch [500/800], Loss: 0.4636\n",
      "Epoch [500/850], Loss: 0.4574\n",
      "Epoch [500/900], Loss: 0.4605\n",
      "Epoch [500/950], Loss: 0.4640\n",
      "Epoch [500/50], Loss: 0.4600\n",
      "Epoch [500/100], Loss: 0.4568\n",
      "Epoch [500/150], Loss: 0.4590\n",
      "Epoch [500/200], Loss: 0.4606\n",
      "Epoch [500/250], Loss: 0.4588\n",
      "Epoch [500/300], Loss: 0.4564\n",
      "Epoch [500/350], Loss: 0.4569\n",
      "Epoch [500/400], Loss: 0.4591\n",
      "Epoch [500/450], Loss: 0.4594\n",
      "Epoch [500/500], Loss: 0.4581\n",
      "Epoch [500/550], Loss: 0.4562\n",
      "Epoch [500/600], Loss: 0.4554\n",
      "Epoch [500/650], Loss: 0.4560\n",
      "Epoch [500/700], Loss: 0.4573\n",
      "Epoch [500/750], Loss: 0.4592\n",
      "Epoch [500/800], Loss: 0.4609\n",
      "Epoch [500/850], Loss: 0.4630\n",
      "Epoch [500/900], Loss: 0.4608\n",
      "Epoch [500/950], Loss: 0.4567\n",
      "Epoch [500/50], Loss: 0.4552\n",
      "Epoch [500/100], Loss: 0.4579\n",
      "Epoch [500/150], Loss: 0.4606\n",
      "Epoch [500/200], Loss: 0.4597\n",
      "Epoch [500/250], Loss: 0.4571\n",
      "Epoch [500/300], Loss: 0.4547\n",
      "Epoch [500/350], Loss: 0.4551\n",
      "Epoch [500/400], Loss: 0.4573\n",
      "Epoch [500/450], Loss: 0.4599\n",
      "Epoch [500/500], Loss: 0.4635\n",
      "Epoch [500/550], Loss: 0.4610\n",
      "Epoch [500/600], Loss: 0.4570\n",
      "Epoch [500/650], Loss: 0.4550\n",
      "Epoch [500/700], Loss: 0.4585\n",
      "Epoch [500/750], Loss: 0.4599\n",
      "Epoch [500/800], Loss: 0.4566\n",
      "Epoch [500/850], Loss: 0.4555\n",
      "Epoch [500/900], Loss: 0.4550\n",
      "Epoch [500/950], Loss: 0.4585\n",
      "Epoch [500/50], Loss: 0.4629\n",
      "Epoch [500/100], Loss: 0.4596\n",
      "Epoch [500/150], Loss: 0.4590\n",
      "Epoch [500/200], Loss: 0.4543\n",
      "Epoch [500/250], Loss: 0.4593\n",
      "Epoch [500/300], Loss: 0.4586\n",
      "Epoch [500/350], Loss: 0.4586\n",
      "Epoch [500/400], Loss: 0.4555\n",
      "Epoch [500/450], Loss: 0.4558\n",
      "Epoch [500/500], Loss: 0.4556\n",
      "Epoch [500/550], Loss: 0.4554\n",
      "Epoch [500/600], Loss: 0.4560\n",
      "Epoch [500/650], Loss: 0.4544\n",
      "Epoch [500/700], Loss: 0.4551\n",
      "Epoch [500/750], Loss: 0.4541\n",
      "Epoch [500/800], Loss: 0.4551\n",
      "Epoch [500/850], Loss: 0.4553\n",
      "Epoch [500/900], Loss: 0.4571\n",
      "Epoch [500/950], Loss: 0.4629\n",
      "Epoch [500/50], Loss: 0.4648\n",
      "Epoch [500/100], Loss: 0.4650\n",
      "Epoch [500/150], Loss: 0.4551\n",
      "Epoch [500/200], Loss: 0.4585\n",
      "Epoch [500/250], Loss: 0.4617\n",
      "Epoch [500/300], Loss: 0.4565\n",
      "Epoch [500/350], Loss: 0.4543\n",
      "Epoch [500/400], Loss: 0.4575\n",
      "Epoch [500/450], Loss: 0.4577\n",
      "Epoch [500/500], Loss: 0.4539\n",
      "Epoch [500/550], Loss: 0.4542\n",
      "Epoch [500/600], Loss: 0.4558\n",
      "Epoch [500/650], Loss: 0.4576\n",
      "Epoch [500/700], Loss: 0.4584\n",
      "Epoch [500/750], Loss: 0.4574\n",
      "Epoch [500/800], Loss: 0.4550\n",
      "Epoch [500/850], Loss: 0.4524\n",
      "Epoch [500/900], Loss: 0.4553\n",
      "Epoch [500/950], Loss: 0.4557\n",
      "Epoch [500/50], Loss: 0.4553\n",
      "Epoch [500/100], Loss: 0.4522\n",
      "Epoch [500/150], Loss: 0.4528\n",
      "Epoch [500/200], Loss: 0.4534\n",
      "Epoch [500/250], Loss: 0.4572\n",
      "Epoch [500/300], Loss: 0.4619\n",
      "Epoch [500/350], Loss: 0.4665\n",
      "Epoch [500/400], Loss: 0.4664\n",
      "Epoch [500/450], Loss: 0.4557\n",
      "Epoch [500/500], Loss: 0.4597\n",
      "Epoch [500/550], Loss: 0.4604\n",
      "Epoch [500/600], Loss: 0.4542\n",
      "Epoch [500/650], Loss: 0.4611\n",
      "Epoch [500/700], Loss: 0.4561\n",
      "Epoch [500/750], Loss: 0.4547\n",
      "Epoch [500/800], Loss: 0.4557\n",
      "Epoch [500/850], Loss: 0.4598\n",
      "Epoch [500/900], Loss: 0.4561\n",
      "Epoch [500/950], Loss: 0.4526\n",
      "Epoch [500/50], Loss: 0.4552\n",
      "Epoch [500/100], Loss: 0.4560\n",
      "Epoch [500/150], Loss: 0.4527\n",
      "Epoch [500/200], Loss: 0.4520\n",
      "Epoch [500/250], Loss: 0.4542\n",
      "Epoch [500/300], Loss: 0.4544\n",
      "Epoch [500/350], Loss: 0.4516\n",
      "Epoch [500/400], Loss: 0.4512\n",
      "Epoch [500/450], Loss: 0.4528\n",
      "Epoch [500/500], Loss: 0.4540\n",
      "Epoch [500/550], Loss: 0.4533\n",
      "Epoch [500/600], Loss: 0.4513\n",
      "Epoch [500/650], Loss: 0.4498\n",
      "Epoch [500/700], Loss: 0.4500\n",
      "Epoch [500/750], Loss: 0.4516\n",
      "Epoch [500/800], Loss: 0.4556\n",
      "Epoch [500/850], Loss: 0.4623\n",
      "Epoch [500/900], Loss: 0.4700\n",
      "Epoch [500/950], Loss: 0.4593\n",
      "Epoch [500/50], Loss: 0.4509\n",
      "Epoch [500/100], Loss: 0.4583\n",
      "Epoch [500/150], Loss: 0.4566\n",
      "Epoch [500/200], Loss: 0.4506\n",
      "Epoch [500/250], Loss: 0.4545\n",
      "Epoch [500/300], Loss: 0.4550\n",
      "Epoch [500/350], Loss: 0.4505\n",
      "Epoch [500/400], Loss: 0.4510\n",
      "Epoch [500/450], Loss: 0.4546\n",
      "Epoch [500/500], Loss: 0.4544\n",
      "Epoch [500/550], Loss: 0.4502\n",
      "Epoch [500/600], Loss: 0.4496\n",
      "Epoch [500/650], Loss: 0.4519\n",
      "Epoch [500/700], Loss: 0.4524\n",
      "Epoch [500/750], Loss: 0.4507\n",
      "Epoch [500/800], Loss: 0.4487\n",
      "Epoch [500/850], Loss: 0.4483\n",
      "Epoch [500/900], Loss: 0.4493\n",
      "Epoch [500/950], Loss: 0.4509\n",
      "Epoch [500/50], Loss: 0.4544\n",
      "Epoch [500/100], Loss: 0.4588\n",
      "Epoch [500/150], Loss: 0.4652\n",
      "Epoch [500/200], Loss: 0.4573\n",
      "Epoch [500/250], Loss: 0.4496\n",
      "Epoch [500/300], Loss: 0.4536\n",
      "Epoch [500/350], Loss: 0.4555\n",
      "Epoch [500/400], Loss: 0.4495\n",
      "Epoch [500/450], Loss: 0.4499\n",
      "Epoch [500/500], Loss: 0.4534\n",
      "Epoch [500/550], Loss: 0.4522\n",
      "Epoch [500/600], Loss: 0.4490\n",
      "Epoch [500/650], Loss: 0.4484\n",
      "Epoch [500/700], Loss: 0.4492\n",
      "Epoch [500/750], Loss: 0.4515\n",
      "Epoch [500/800], Loss: 0.4534\n",
      "Epoch [500/850], Loss: 0.4493\n",
      "Epoch [500/900], Loss: 0.4489\n",
      "Epoch [500/950], Loss: 0.4479\n",
      "Epoch [500/50], Loss: 0.4492\n",
      "Epoch [500/100], Loss: 0.4552\n",
      "Epoch [500/150], Loss: 0.4601\n",
      "Epoch [500/200], Loss: 0.4626\n",
      "Epoch [500/250], Loss: 0.4496\n",
      "Epoch [500/300], Loss: 0.4495\n",
      "Epoch [500/350], Loss: 0.4578\n",
      "Epoch [500/400], Loss: 0.4549\n",
      "Epoch [500/450], Loss: 0.4495\n",
      "Epoch [500/500], Loss: 0.4497\n",
      "Epoch [500/550], Loss: 0.4541\n",
      "Epoch [500/600], Loss: 0.4496\n",
      "Epoch [500/650], Loss: 0.4476\n",
      "Epoch [500/700], Loss: 0.4513\n",
      "Epoch [500/750], Loss: 0.4490\n",
      "Epoch [500/800], Loss: 0.4491\n",
      "Epoch [500/850], Loss: 0.4479\n",
      "Epoch [500/900], Loss: 0.4459\n",
      "Epoch [500/950], Loss: 0.4489\n",
      "Epoch [500/50], Loss: 0.4495\n",
      "Epoch [500/100], Loss: 0.4505\n",
      "Epoch [500/150], Loss: 0.4534\n",
      "Epoch [500/200], Loss: 0.4498\n",
      "Epoch [500/250], Loss: 0.4505\n",
      "Epoch [500/300], Loss: 0.4470\n",
      "Epoch [500/350], Loss: 0.4450\n",
      "Epoch [500/400], Loss: 0.4460\n",
      "Epoch [500/450], Loss: 0.4459\n",
      "Epoch [500/500], Loss: 0.4503\n",
      "Epoch [500/550], Loss: 0.4640\n",
      "Epoch [500/600], Loss: 0.4855\n",
      "Epoch [500/650], Loss: 0.4638\n",
      "Epoch [500/700], Loss: 0.4502\n",
      "Epoch [500/750], Loss: 0.4658\n",
      "Epoch [500/800], Loss: 0.4519\n",
      "Epoch [500/850], Loss: 0.4569\n",
      "Epoch [500/900], Loss: 0.4562\n",
      "Epoch [500/950], Loss: 0.4502\n",
      "Epoch [500/50], Loss: 0.4601\n",
      "Epoch [500/100], Loss: 0.4517\n",
      "Epoch [500/150], Loss: 0.4528\n",
      "Epoch [500/200], Loss: 0.4541\n",
      "Epoch [500/250], Loss: 0.4490\n",
      "Epoch [500/300], Loss: 0.4539\n",
      "Epoch [500/350], Loss: 0.4486\n",
      "Epoch [500/400], Loss: 0.4507\n",
      "Epoch [500/450], Loss: 0.4507\n",
      "Epoch [500/500], Loss: 0.4472\n",
      "Epoch [500/550], Loss: 0.4510\n",
      "Epoch [500/600], Loss: 0.4483\n",
      "Epoch [500/650], Loss: 0.4469\n",
      "Epoch [500/700], Loss: 0.4492\n",
      "Epoch [500/750], Loss: 0.4465\n",
      "Epoch [500/800], Loss: 0.4464\n",
      "Epoch [500/850], Loss: 0.4476\n",
      "Epoch [500/900], Loss: 0.4458\n",
      "Epoch [500/950], Loss: 0.4446\n",
      "Epoch [500/50], Loss: 0.4454\n",
      "Epoch [500/100], Loss: 0.4461\n",
      "Epoch [500/150], Loss: 0.4453\n",
      "Epoch [500/200], Loss: 0.4440\n",
      "Epoch [500/250], Loss: 0.4430\n",
      "Epoch [500/300], Loss: 0.4430\n",
      "Epoch [500/350], Loss: 0.4444\n",
      "Epoch [500/400], Loss: 0.4471\n",
      "Epoch [500/450], Loss: 0.4541\n",
      "Epoch [500/500], Loss: 0.4689\n",
      "Epoch [500/550], Loss: 0.4842\n",
      "Epoch [500/600], Loss: 0.4522\n",
      "Epoch [500/650], Loss: 0.4622\n",
      "Epoch [500/700], Loss: 0.4584\n",
      "Epoch [500/750], Loss: 0.4557\n",
      "Epoch [500/800], Loss: 0.4545\n",
      "Epoch [500/850], Loss: 0.4555\n",
      "Epoch [500/900], Loss: 0.4512\n",
      "Epoch [500/950], Loss: 0.4567\n",
      "Epoch [500/50], Loss: 0.4478\n",
      "Epoch [500/100], Loss: 0.4539\n",
      "Epoch [500/150], Loss: 0.4495\n",
      "Epoch [500/200], Loss: 0.4515\n",
      "Epoch [500/250], Loss: 0.4476\n",
      "Epoch [500/300], Loss: 0.4481\n",
      "Epoch [500/350], Loss: 0.4479\n",
      "Epoch [500/400], Loss: 0.4471\n",
      "Epoch [500/450], Loss: 0.4463\n",
      "Epoch [500/500], Loss: 0.4470\n",
      "Epoch [500/550], Loss: 0.4454\n",
      "Epoch [500/600], Loss: 0.4453\n",
      "Epoch [500/650], Loss: 0.4455\n",
      "Epoch [500/700], Loss: 0.4447\n",
      "Epoch [500/750], Loss: 0.4442\n",
      "Epoch [500/800], Loss: 0.4435\n",
      "Epoch [500/850], Loss: 0.4441\n",
      "Epoch [500/900], Loss: 0.4436\n",
      "Epoch [500/950], Loss: 0.4431\n",
      "Epoch [500/50], Loss: 0.4429\n",
      "Epoch [500/100], Loss: 0.4424\n",
      "Epoch [500/150], Loss: 0.4422\n",
      "Epoch [500/200], Loss: 0.4425\n",
      "Epoch [500/250], Loss: 0.4436\n",
      "Epoch [500/300], Loss: 0.4479\n",
      "Epoch [500/350], Loss: 0.4609\n",
      "Epoch [500/400], Loss: 0.4769\n",
      "Epoch [500/450], Loss: 0.4740\n",
      "Epoch [500/500], Loss: 0.4462\n",
      "Epoch [500/550], Loss: 0.4612\n",
      "Epoch [500/600], Loss: 0.4575\n",
      "Epoch [500/650], Loss: 0.4486\n",
      "Epoch [500/700], Loss: 0.4568\n",
      "Epoch [500/750], Loss: 0.4462\n",
      "Epoch [500/800], Loss: 0.4542\n",
      "Epoch [500/850], Loss: 0.4466\n",
      "Epoch [500/900], Loss: 0.4502\n",
      "Epoch [500/950], Loss: 0.4482\n",
      "Epoch [500/50], Loss: 0.4465\n",
      "Epoch [500/100], Loss: 0.4499\n",
      "Epoch [500/150], Loss: 0.4447\n",
      "Epoch [500/200], Loss: 0.4475\n",
      "Epoch [500/250], Loss: 0.4458\n",
      "Epoch [500/300], Loss: 0.4447\n",
      "Epoch [500/350], Loss: 0.4457\n",
      "Epoch [500/400], Loss: 0.4442\n",
      "Epoch [500/450], Loss: 0.4435\n",
      "Epoch [500/500], Loss: 0.4447\n",
      "Epoch [500/550], Loss: 0.4428\n",
      "Epoch [500/600], Loss: 0.4420\n",
      "Epoch [500/650], Loss: 0.4434\n",
      "Epoch [500/700], Loss: 0.4419\n",
      "Epoch [500/750], Loss: 0.4408\n",
      "Epoch [500/800], Loss: 0.4413\n",
      "Epoch [500/850], Loss: 0.4412\n",
      "Epoch [500/900], Loss: 0.4413\n",
      "Epoch [500/950], Loss: 0.4411\n",
      "Epoch [500/50], Loss: 0.4402\n",
      "Epoch [500/100], Loss: 0.4391\n",
      "Epoch [500/150], Loss: 0.4388\n",
      "Epoch [500/200], Loss: 0.4387\n",
      "Epoch [500/250], Loss: 0.4383\n",
      "Epoch [500/300], Loss: 0.4377\n",
      "Epoch [500/350], Loss: 0.4376\n",
      "Epoch [500/400], Loss: 0.4388\n",
      "Epoch [500/450], Loss: 0.4471\n",
      "Epoch [500/500], Loss: 0.4906\n",
      "Epoch [500/550], Loss: 0.5575\n",
      "Epoch [500/600], Loss: 0.4936\n",
      "Epoch [500/650], Loss: 0.4849\n",
      "Epoch [500/700], Loss: 0.4738\n",
      "Epoch [500/750], Loss: 0.4880\n",
      "Epoch [500/800], Loss: 0.4614\n",
      "Epoch [500/850], Loss: 0.4800\n",
      "Epoch [500/900], Loss: 0.4702\n",
      "Epoch [500/950], Loss: 0.4656\n",
      "Epoch [500/50], Loss: 0.4747\n",
      "Epoch [500/100], Loss: 0.4663\n",
      "Epoch [500/150], Loss: 0.4668\n",
      "Epoch [500/200], Loss: 0.4664\n",
      "Epoch [500/250], Loss: 0.4615\n",
      "Epoch [500/300], Loss: 0.4642\n",
      "Epoch [500/350], Loss: 0.4622\n",
      "Epoch [500/400], Loss: 0.4603\n",
      "Epoch [500/450], Loss: 0.4600\n",
      "Epoch [500/500], Loss: 0.4597\n",
      "Epoch [500/550], Loss: 0.4587\n",
      "Epoch [500/600], Loss: 0.4581\n",
      "Epoch [500/650], Loss: 0.4574\n",
      "Epoch [500/700], Loss: 0.4563\n",
      "Epoch [500/750], Loss: 0.4558\n",
      "Epoch [500/800], Loss: 0.4553\n",
      "Epoch [500/850], Loss: 0.4553\n",
      "Epoch [500/900], Loss: 0.4538\n",
      "Epoch [500/950], Loss: 0.4535\n",
      "Epoch [500/50], Loss: 0.4527\n",
      "Epoch [500/100], Loss: 0.4523\n",
      "Epoch [500/150], Loss: 0.4518\n",
      "Epoch [500/200], Loss: 0.4512\n",
      "Epoch [500/250], Loss: 0.4509\n",
      "Epoch [500/300], Loss: 0.4505\n",
      "Epoch [500/350], Loss: 0.4502\n",
      "Epoch [500/400], Loss: 0.4497\n",
      "Epoch [500/450], Loss: 0.4494\n",
      "Epoch [500/500], Loss: 0.4490\n",
      "Epoch [500/550], Loss: 0.4487\n",
      "Epoch [500/600], Loss: 0.4483\n",
      "Epoch [500/650], Loss: 0.4480\n",
      "Epoch [500/700], Loss: 0.4477\n",
      "Epoch [500/750], Loss: 0.4474\n",
      "Epoch [500/800], Loss: 0.4470\n",
      "Epoch [500/850], Loss: 0.4467\n",
      "Epoch [500/900], Loss: 0.4464\n",
      "Epoch [500/950], Loss: 0.4461\n",
      "Epoch [500/50], Loss: 0.4458\n",
      "Epoch [500/100], Loss: 0.4458\n",
      "Epoch [500/150], Loss: 0.4454\n",
      "Epoch [500/200], Loss: 0.4450\n",
      "Epoch [500/250], Loss: 0.4448\n",
      "Epoch [500/300], Loss: 0.4444\n",
      "Epoch [500/350], Loss: 0.4442\n",
      "Epoch [500/400], Loss: 0.4440\n",
      "Epoch [500/450], Loss: 0.4436\n",
      "Epoch [500/500], Loss: 0.4433\n",
      "Epoch [500/550], Loss: 0.4432\n",
      "Epoch [500/600], Loss: 0.4428\n",
      "Epoch [500/650], Loss: 0.4425\n",
      "Epoch [500/700], Loss: 0.4423\n",
      "Epoch [500/750], Loss: 0.4422\n",
      "Epoch [500/800], Loss: 0.4419\n",
      "Epoch [500/850], Loss: 0.4415\n",
      "Epoch [500/900], Loss: 0.4413\n",
      "Epoch [500/950], Loss: 0.4412\n",
      "Epoch [500/50], Loss: 0.4411\n",
      "Epoch [500/100], Loss: 0.4410\n",
      "Epoch [500/150], Loss: 0.4410\n",
      "Epoch [500/200], Loss: 0.4408\n",
      "Epoch [500/250], Loss: 0.4405\n",
      "Epoch [500/300], Loss: 0.4402\n",
      "Epoch [500/350], Loss: 0.4400\n",
      "Epoch [500/400], Loss: 0.4401\n",
      "Epoch [500/450], Loss: 0.4406\n",
      "Epoch [500/500], Loss: 0.4424\n",
      "Epoch [500/550], Loss: 0.4466\n",
      "Epoch [500/600], Loss: 0.4516\n",
      "Epoch [500/650], Loss: 0.4520\n",
      "Epoch [500/700], Loss: 0.4437\n",
      "Epoch [500/750], Loss: 0.4411\n",
      "Epoch [500/800], Loss: 0.4456\n",
      "Epoch [500/850], Loss: 0.4456\n",
      "Epoch [500/900], Loss: 0.4424\n",
      "Epoch [500/950], Loss: 0.4405\n",
      "Epoch [500/50], Loss: 0.4425\n",
      "Epoch [500/100], Loss: 0.4435\n",
      "Epoch [500/150], Loss: 0.4398\n",
      "Epoch [500/200], Loss: 0.4393\n",
      "Epoch [500/250], Loss: 0.4417\n",
      "Epoch [500/300], Loss: 0.4408\n",
      "Epoch [500/350], Loss: 0.4393\n",
      "Epoch [500/400], Loss: 0.4393\n",
      "Epoch [500/450], Loss: 0.4390\n",
      "Epoch [500/500], Loss: 0.4382\n",
      "Epoch [500/550], Loss: 0.4389\n",
      "Epoch [500/600], Loss: 0.4402\n",
      "Epoch [500/650], Loss: 0.4398\n",
      "Epoch [500/700], Loss: 0.4398\n",
      "Epoch [500/750], Loss: 0.4408\n",
      "Epoch [500/800], Loss: 0.4419\n",
      "Epoch [500/850], Loss: 0.4420\n",
      "Epoch [500/900], Loss: 0.4438\n",
      "Epoch [500/950], Loss: 0.4456\n",
      "Epoch [500/50], Loss: 0.4458\n",
      "Epoch [500/100], Loss: 0.4391\n",
      "Epoch [500/150], Loss: 0.4392\n",
      "Epoch [500/200], Loss: 0.4404\n",
      "Epoch [500/250], Loss: 0.4385\n",
      "Epoch [500/300], Loss: 0.4414\n",
      "Epoch [500/350], Loss: 0.4435\n",
      "Epoch [500/400], Loss: 0.4413\n",
      "Epoch [500/450], Loss: 0.4417\n",
      "Epoch [500/500], Loss: 0.4441\n",
      "Epoch [500/550], Loss: 0.4384\n",
      "Epoch [500/600], Loss: 0.4373\n",
      "Epoch [500/650], Loss: 0.4395\n",
      "Epoch [500/700], Loss: 0.4379\n",
      "Epoch [500/750], Loss: 0.4398\n",
      "Epoch [500/800], Loss: 0.4438\n",
      "Epoch [500/850], Loss: 0.4440\n",
      "Epoch [500/900], Loss: 0.4438\n",
      "Epoch [500/950], Loss: 0.4467\n",
      "Epoch [500/50], Loss: 0.4398\n",
      "Epoch [500/100], Loss: 0.4372\n",
      "Epoch [500/150], Loss: 0.4380\n",
      "Epoch [500/200], Loss: 0.4378\n",
      "Epoch [500/250], Loss: 0.4409\n",
      "Epoch [500/300], Loss: 0.4429\n",
      "Epoch [500/350], Loss: 0.4425\n",
      "Epoch [500/400], Loss: 0.4405\n",
      "Epoch [500/450], Loss: 0.4378\n",
      "Epoch [500/500], Loss: 0.4352\n",
      "Epoch [500/550], Loss: 0.4367\n",
      "Epoch [500/600], Loss: 0.4393\n",
      "Epoch [500/650], Loss: 0.4406\n",
      "Epoch [500/700], Loss: 0.4432\n",
      "Epoch [500/750], Loss: 0.4426\n",
      "Epoch [500/800], Loss: 0.4396\n",
      "Epoch [500/850], Loss: 0.4382\n",
      "Epoch [500/900], Loss: 0.4365\n",
      "Epoch [500/950], Loss: 0.4344\n",
      "Epoch [500/50], Loss: 0.4362\n",
      "Epoch [500/100], Loss: 0.4384\n",
      "Epoch [500/150], Loss: 0.4400\n",
      "Epoch [500/200], Loss: 0.4462\n",
      "Epoch [500/250], Loss: 0.4518\n",
      "Epoch [500/300], Loss: 0.4514\n",
      "Epoch [500/350], Loss: 0.4452\n",
      "Epoch [500/400], Loss: 0.4391\n",
      "Epoch [500/450], Loss: 0.4381\n",
      "Epoch [500/500], Loss: 0.4443\n",
      "Epoch [500/550], Loss: 0.4414\n",
      "Epoch [500/600], Loss: 0.4358\n",
      "Epoch [500/650], Loss: 0.4400\n",
      "Epoch [500/700], Loss: 0.4379\n",
      "Epoch [500/750], Loss: 0.4382\n",
      "Epoch [500/800], Loss: 0.4389\n",
      "Epoch [500/850], Loss: 0.4349\n",
      "Epoch [500/900], Loss: 0.4381\n",
      "Epoch [500/950], Loss: 0.4386\n",
      "Epoch [500/50], Loss: 0.4357\n",
      "Epoch [500/100], Loss: 0.4372\n",
      "Epoch [500/150], Loss: 0.4343\n",
      "Epoch [500/200], Loss: 0.4344\n",
      "Epoch [500/250], Loss: 0.4361\n",
      "Epoch [500/300], Loss: 0.4343\n",
      "Epoch [500/350], Loss: 0.4357\n",
      "Epoch [500/400], Loss: 0.4383\n",
      "Epoch [500/450], Loss: 0.4412\n",
      "Epoch [500/500], Loss: 0.4506\n",
      "Epoch [500/550], Loss: 0.4643\n",
      "Epoch [500/600], Loss: 0.4483\n",
      "Epoch [500/650], Loss: 0.4399\n",
      "Epoch [500/700], Loss: 0.4439\n",
      "Epoch [500/750], Loss: 0.4469\n",
      "Epoch [500/800], Loss: 0.4379\n",
      "Epoch [500/850], Loss: 0.4390\n",
      "Epoch [500/900], Loss: 0.4453\n",
      "Epoch [500/950], Loss: 0.4365\n",
      "Epoch [500/50], Loss: 0.4376\n",
      "Epoch [500/100], Loss: 0.4404\n",
      "Epoch [500/150], Loss: 0.4387\n",
      "Epoch [500/200], Loss: 0.4358\n",
      "Epoch [500/250], Loss: 0.4361\n",
      "Epoch [500/300], Loss: 0.4386\n",
      "Epoch [500/350], Loss: 0.4350\n",
      "Epoch [500/400], Loss: 0.4343\n",
      "Epoch [500/450], Loss: 0.4357\n",
      "Epoch [500/500], Loss: 0.4374\n",
      "Epoch [500/550], Loss: 0.4378\n",
      "Epoch [500/600], Loss: 0.4340\n",
      "Epoch [500/650], Loss: 0.4325\n",
      "Epoch [500/700], Loss: 0.4337\n",
      "Epoch [500/750], Loss: 0.4356\n",
      "Epoch [500/800], Loss: 0.4395\n",
      "Epoch [500/850], Loss: 0.4402\n",
      "Epoch [500/900], Loss: 0.4404\n",
      "Epoch [500/950], Loss: 0.4381\n",
      "Epoch [500/50], Loss: 0.4350\n",
      "Epoch [500/100], Loss: 0.4318\n",
      "Epoch [500/150], Loss: 0.4310\n",
      "Epoch [500/200], Loss: 0.4326\n",
      "Epoch [500/250], Loss: 0.4357\n",
      "Epoch [500/300], Loss: 0.4414\n",
      "Epoch [500/350], Loss: 0.4488\n",
      "Epoch [500/400], Loss: 0.4530\n",
      "Epoch [500/450], Loss: 0.4407\n",
      "Epoch [500/500], Loss: 0.4329\n",
      "Epoch [500/550], Loss: 0.4386\n",
      "Epoch [500/600], Loss: 0.4445\n",
      "Epoch [500/650], Loss: 0.4411\n",
      "Epoch [500/700], Loss: 0.4323\n",
      "Epoch [500/750], Loss: 0.4343\n",
      "Epoch [500/800], Loss: 0.4399\n",
      "Epoch [500/850], Loss: 0.4358\n",
      "Epoch [500/900], Loss: 0.4318\n",
      "Epoch [500/950], Loss: 0.4340\n",
      "Epoch [500/50], Loss: 0.4357\n",
      "Epoch [500/100], Loss: 0.4355\n",
      "Epoch [500/150], Loss: 0.4332\n",
      "Epoch [500/200], Loss: 0.4311\n",
      "Epoch [500/250], Loss: 0.4305\n",
      "Epoch [500/300], Loss: 0.4323\n",
      "Epoch [500/350], Loss: 0.4343\n",
      "Epoch [500/400], Loss: 0.4336\n",
      "Epoch [500/450], Loss: 0.4334\n",
      "Epoch [500/500], Loss: 0.4333\n",
      "Epoch [500/550], Loss: 0.4330\n",
      "Epoch [500/600], Loss: 0.4312\n",
      "Epoch [500/650], Loss: 0.4303\n",
      "Epoch [500/700], Loss: 0.4314\n",
      "Epoch [500/750], Loss: 0.4344\n",
      "Epoch [500/800], Loss: 0.4362\n",
      "Epoch [500/850], Loss: 0.4429\n",
      "Epoch [500/900], Loss: 0.4555\n",
      "Epoch [500/950], Loss: 0.4708\n",
      "Epoch [500/50], Loss: 0.4474\n",
      "Epoch [500/100], Loss: 0.4357\n",
      "Epoch [500/150], Loss: 0.4534\n",
      "Epoch [500/200], Loss: 0.4419\n",
      "Epoch [500/250], Loss: 0.4440\n",
      "Epoch [500/300], Loss: 0.4388\n",
      "Epoch [500/350], Loss: 0.4442\n",
      "Epoch [500/400], Loss: 0.4349\n",
      "Epoch [500/450], Loss: 0.4408\n",
      "Epoch [500/500], Loss: 0.4352\n",
      "Epoch [500/550], Loss: 0.4380\n",
      "Epoch [500/600], Loss: 0.4340\n",
      "Epoch [500/650], Loss: 0.4357\n",
      "Epoch [500/700], Loss: 0.4345\n",
      "Epoch [500/750], Loss: 0.4335\n",
      "Epoch [500/800], Loss: 0.4343\n",
      "Epoch [500/850], Loss: 0.4325\n",
      "Epoch [500/900], Loss: 0.4327\n",
      "Epoch [500/950], Loss: 0.4314\n",
      "Epoch [500/50], Loss: 0.4323\n",
      "Epoch [500/100], Loss: 0.4305\n",
      "Epoch [500/150], Loss: 0.4302\n",
      "Epoch [500/200], Loss: 0.4300\n",
      "Epoch [500/250], Loss: 0.4310\n",
      "Epoch [500/300], Loss: 0.4399\n",
      "Epoch [500/350], Loss: 0.4670\n",
      "Epoch [500/400], Loss: 0.4586\n",
      "Epoch [500/450], Loss: 0.4420\n",
      "Epoch [500/500], Loss: 0.4358\n",
      "Epoch [500/550], Loss: 0.4509\n",
      "Epoch [500/600], Loss: 0.4396\n",
      "Epoch [500/650], Loss: 0.4340\n",
      "Epoch [500/700], Loss: 0.4401\n",
      "Epoch [500/750], Loss: 0.4366\n",
      "Epoch [500/800], Loss: 0.4339\n",
      "Epoch [500/850], Loss: 0.4388\n",
      "Epoch [500/900], Loss: 0.4338\n",
      "Epoch [500/950], Loss: 0.4327\n",
      "Epoch [500/50], Loss: 0.4359\n",
      "Epoch [500/100], Loss: 0.4329\n",
      "Epoch [500/150], Loss: 0.4322\n",
      "Epoch [500/200], Loss: 0.4324\n",
      "Epoch [500/250], Loss: 0.4330\n",
      "Epoch [500/300], Loss: 0.4302\n",
      "Epoch [500/350], Loss: 0.4299\n",
      "Epoch [500/400], Loss: 0.4319\n",
      "Epoch [500/450], Loss: 0.4294\n",
      "Epoch [500/500], Loss: 0.4292\n",
      "Epoch [500/550], Loss: 0.4288\n",
      "Epoch [500/600], Loss: 0.4274\n",
      "Epoch [500/650], Loss: 0.4287\n",
      "Epoch [500/700], Loss: 0.4286\n",
      "Epoch [500/750], Loss: 0.4290\n",
      "Epoch [500/800], Loss: 0.4327\n",
      "Epoch [500/850], Loss: 0.4424\n",
      "Epoch [500/900], Loss: 0.4636\n",
      "Epoch [500/950], Loss: 0.4777\n",
      "Epoch [500/50], Loss: 0.4359\n",
      "Epoch [500/100], Loss: 0.4548\n",
      "Epoch [500/150], Loss: 0.4544\n",
      "Epoch [500/200], Loss: 0.4379\n",
      "Epoch [500/250], Loss: 0.4524\n",
      "Epoch [500/300], Loss: 0.4390\n",
      "Epoch [500/350], Loss: 0.4445\n",
      "Epoch [500/400], Loss: 0.4424\n",
      "Epoch [500/450], Loss: 0.4390\n",
      "Epoch [500/500], Loss: 0.4449\n",
      "Epoch [500/550], Loss: 0.4330\n",
      "Epoch [500/600], Loss: 0.4410\n",
      "Epoch [500/650], Loss: 0.4337\n",
      "Epoch [500/700], Loss: 0.4375\n",
      "Epoch [500/750], Loss: 0.4361\n",
      "Epoch [500/800], Loss: 0.4329\n",
      "Epoch [500/850], Loss: 0.4324\n",
      "Epoch [500/900], Loss: 0.4323\n",
      "Epoch [500/950], Loss: 0.4313\n",
      "Epoch [500/50], Loss: 0.4310\n",
      "Epoch [500/100], Loss: 0.4314\n",
      "Epoch [500/150], Loss: 0.4297\n",
      "Epoch [500/200], Loss: 0.4295\n",
      "Epoch [500/250], Loss: 0.4293\n",
      "Epoch [500/300], Loss: 0.4284\n",
      "Epoch [500/350], Loss: 0.4280\n",
      "Epoch [500/400], Loss: 0.4273\n",
      "Epoch [500/450], Loss: 0.4272\n",
      "Epoch [500/500], Loss: 0.4266\n",
      "Epoch [500/550], Loss: 0.4259\n",
      "Epoch [500/600], Loss: 0.4256\n",
      "Epoch [500/650], Loss: 0.4251\n",
      "Epoch [500/700], Loss: 0.4244\n",
      "Epoch [500/750], Loss: 0.4241\n",
      "Epoch [500/800], Loss: 0.4239\n",
      "Epoch [500/850], Loss: 0.4237\n",
      "Epoch [500/900], Loss: 0.4232\n",
      "Epoch [500/950], Loss: 0.4228\n",
      "Epoch [500/50], Loss: 0.4238\n",
      "Epoch [500/100], Loss: 0.4354\n",
      "Epoch [500/150], Loss: 0.5037\n",
      "Epoch [500/200], Loss: 0.5875\n",
      "Epoch [500/250], Loss: 0.4947\n",
      "Epoch [500/300], Loss: 0.4864\n",
      "Epoch [500/350], Loss: 0.4752\n",
      "Epoch [500/400], Loss: 0.4980\n",
      "Epoch [500/450], Loss: 0.4612\n",
      "Epoch [500/500], Loss: 0.4798\n",
      "Epoch [500/550], Loss: 0.4677\n",
      "Epoch [500/600], Loss: 0.4577\n",
      "Epoch [500/650], Loss: 0.4699\n",
      "Epoch [500/700], Loss: 0.4670\n",
      "Epoch [500/750], Loss: 0.4613\n",
      "Epoch [500/800], Loss: 0.4647\n",
      "Epoch [500/850], Loss: 0.4572\n",
      "Epoch [500/900], Loss: 0.5061\n",
      "Epoch [500/950], Loss: 0.4736\n",
      "Epoch [500/50], Loss: 0.4911\n",
      "Epoch [500/100], Loss: 0.4623\n",
      "Epoch [500/150], Loss: 0.4701\n",
      "Epoch [500/200], Loss: 0.4825\n",
      "Epoch [500/250], Loss: 0.4706\n",
      "Epoch [500/300], Loss: 0.4615\n",
      "Epoch [500/350], Loss: 0.4671\n",
      "Epoch [500/400], Loss: 0.4639\n",
      "Epoch [500/450], Loss: 0.4588\n",
      "Epoch [500/500], Loss: 0.4593\n",
      "Epoch [500/550], Loss: 0.4590\n",
      "Epoch [500/600], Loss: 0.4576\n",
      "Epoch [500/650], Loss: 0.4554\n",
      "Epoch [500/700], Loss: 0.4556\n",
      "Epoch [500/750], Loss: 0.4553\n",
      "Epoch [500/800], Loss: 0.4534\n",
      "Epoch [500/850], Loss: 0.4520\n",
      "Epoch [500/900], Loss: 0.4513\n",
      "Epoch [500/950], Loss: 0.4509\n",
      "Epoch [500/50], Loss: 0.4492\n",
      "Epoch [500/100], Loss: 0.4484\n",
      "Epoch [500/150], Loss: 0.4477\n",
      "Epoch [500/200], Loss: 0.4468\n",
      "Epoch [500/250], Loss: 0.4463\n",
      "Epoch [500/300], Loss: 0.4452\n",
      "Epoch [500/350], Loss: 0.4447\n",
      "Epoch [500/400], Loss: 0.4439\n",
      "Epoch [500/450], Loss: 0.4433\n",
      "Epoch [500/500], Loss: 0.4426\n",
      "Epoch [500/550], Loss: 0.4421\n",
      "Epoch [500/600], Loss: 0.4420\n",
      "Epoch [500/650], Loss: 0.4429\n",
      "Epoch [500/700], Loss: 0.4407\n",
      "Epoch [500/750], Loss: 0.4404\n",
      "Epoch [500/800], Loss: 0.4405\n",
      "Epoch [500/850], Loss: 0.4393\n",
      "Epoch [500/900], Loss: 0.4398\n",
      "Epoch [500/950], Loss: 0.4383\n",
      "Epoch [500/50], Loss: 0.4384\n",
      "Epoch [500/100], Loss: 0.4378\n",
      "Epoch [500/150], Loss: 0.4369\n",
      "Epoch [500/200], Loss: 0.4371\n",
      "Epoch [500/250], Loss: 0.4363\n",
      "Epoch [500/300], Loss: 0.4357\n",
      "Epoch [500/350], Loss: 0.4357\n",
      "Epoch [500/400], Loss: 0.4352\n",
      "Epoch [500/450], Loss: 0.4345\n",
      "Epoch [500/500], Loss: 0.4339\n",
      "Epoch [500/550], Loss: 0.4336\n",
      "Epoch [500/600], Loss: 0.4337\n",
      "Epoch [500/650], Loss: 0.4343\n",
      "Epoch [500/700], Loss: 0.4371\n",
      "Epoch [500/750], Loss: 0.4356\n",
      "Epoch [500/800], Loss: 0.4331\n",
      "Epoch [500/850], Loss: 0.4317\n",
      "Epoch [500/900], Loss: 0.4334\n",
      "Epoch [500/950], Loss: 0.4341\n",
      "Epoch [500/50], Loss: 0.4313\n",
      "Epoch [500/100], Loss: 0.4310\n",
      "Epoch [500/150], Loss: 0.4328\n",
      "Epoch [500/200], Loss: 0.4323\n",
      "Epoch [500/250], Loss: 0.4306\n",
      "Epoch [500/300], Loss: 0.4294\n",
      "Epoch [500/350], Loss: 0.4299\n",
      "Epoch [500/400], Loss: 0.4310\n",
      "Epoch [500/450], Loss: 0.4314\n",
      "Epoch [500/500], Loss: 0.4322\n",
      "Epoch [500/550], Loss: 0.4305\n",
      "Epoch [500/600], Loss: 0.4293\n",
      "Epoch [500/650], Loss: 0.4281\n",
      "Epoch [500/700], Loss: 0.4275\n",
      "Epoch [500/750], Loss: 0.4275\n",
      "Epoch [500/800], Loss: 0.4283\n",
      "Epoch [500/850], Loss: 0.4307\n",
      "Epoch [500/900], Loss: 0.4358\n",
      "Epoch [500/950], Loss: 0.4515\n",
      "Epoch [500/50], Loss: 0.4395\n",
      "Epoch [500/100], Loss: 0.4303\n",
      "Epoch [500/150], Loss: 0.4310\n",
      "Epoch [500/200], Loss: 0.4331\n",
      "Epoch [500/250], Loss: 0.4314\n",
      "Epoch [500/300], Loss: 0.4300\n",
      "Epoch [500/350], Loss: 0.4296\n",
      "Epoch [500/400], Loss: 0.4305\n",
      "Epoch [500/450], Loss: 0.4303\n",
      "Epoch [500/500], Loss: 0.4278\n",
      "Epoch [500/550], Loss: 0.4293\n",
      "Epoch [500/600], Loss: 0.4320\n",
      "Epoch [500/650], Loss: 0.4310\n",
      "Epoch [500/700], Loss: 0.4275\n",
      "Epoch [500/750], Loss: 0.4272\n",
      "Epoch [500/800], Loss: 0.4287\n",
      "Epoch [500/850], Loss: 0.4299\n",
      "Epoch [500/900], Loss: 0.4315\n",
      "Epoch [500/950], Loss: 0.4283\n",
      "Epoch [500/50], Loss: 0.4257\n",
      "Epoch [500/100], Loss: 0.4254\n",
      "Epoch [500/150], Loss: 0.4269\n",
      "Epoch [500/200], Loss: 0.4290\n",
      "Epoch [500/250], Loss: 0.4292\n",
      "Epoch [500/300], Loss: 0.4308\n",
      "Epoch [500/350], Loss: 0.4310\n",
      "Epoch [500/400], Loss: 0.4306\n",
      "Epoch [500/450], Loss: 0.4279\n",
      "Epoch [500/500], Loss: 0.4255\n",
      "Epoch [500/550], Loss: 0.4245\n",
      "Epoch [500/600], Loss: 0.4247\n",
      "Epoch [500/650], Loss: 0.4246\n",
      "Epoch [500/700], Loss: 0.4243\n",
      "Epoch [500/750], Loss: 0.4252\n",
      "Epoch [500/800], Loss: 0.4304\n",
      "Epoch [500/850], Loss: 0.4526\n",
      "Epoch [500/900], Loss: 0.4521\n",
      "Epoch [500/950], Loss: 0.4519\n",
      "Epoch [500/50], Loss: 0.4385\n",
      "Epoch [500/100], Loss: 0.4401\n",
      "Epoch [500/150], Loss: 0.4372\n",
      "Epoch [500/200], Loss: 0.4401\n",
      "Epoch [500/250], Loss: 0.4309\n",
      "Epoch [500/300], Loss: 0.4422\n",
      "Epoch [500/350], Loss: 0.4295\n",
      "Epoch [500/400], Loss: 0.4355\n",
      "Epoch [500/450], Loss: 0.4321\n",
      "Epoch [500/500], Loss: 0.4313\n",
      "Epoch [500/550], Loss: 0.4302\n",
      "Epoch [500/600], Loss: 0.4301\n",
      "Epoch [500/650], Loss: 0.4283\n",
      "Epoch [500/700], Loss: 0.4279\n",
      "Epoch [500/750], Loss: 0.4293\n",
      "Epoch [500/800], Loss: 0.4272\n",
      "Epoch [500/850], Loss: 0.4272\n",
      "Epoch [500/900], Loss: 0.4275\n",
      "Epoch [500/950], Loss: 0.4262\n",
      "Epoch [500/50], Loss: 0.4260\n",
      "Epoch [500/100], Loss: 0.4256\n",
      "Epoch [500/150], Loss: 0.4257\n",
      "Epoch [500/200], Loss: 0.4256\n",
      "Epoch [500/250], Loss: 0.4249\n",
      "Epoch [500/300], Loss: 0.4242\n",
      "Epoch [500/350], Loss: 0.4236\n",
      "Epoch [500/400], Loss: 0.4231\n",
      "Epoch [500/450], Loss: 0.4225\n",
      "Epoch [500/500], Loss: 0.4220\n",
      "Epoch [500/550], Loss: 0.4219\n",
      "Epoch [500/600], Loss: 0.4214\n",
      "Epoch [500/650], Loss: 0.4216\n",
      "Epoch [500/700], Loss: 0.4239\n",
      "Epoch [500/750], Loss: 0.4369\n",
      "Epoch [500/800], Loss: 0.4786\n",
      "Epoch [500/850], Loss: 0.5635\n",
      "Epoch [500/900], Loss: 0.4914\n",
      "Epoch [500/950], Loss: 0.4905\n",
      "Epoch [500/50], Loss: 0.4933\n",
      "Epoch [500/100], Loss: 0.4542\n",
      "Epoch [500/150], Loss: 0.4623\n",
      "Epoch [500/200], Loss: 0.4679\n",
      "Epoch [500/250], Loss: 0.4604\n",
      "Epoch [500/300], Loss: 0.4637\n",
      "Epoch [500/350], Loss: 0.4595\n",
      "Epoch [500/400], Loss: 0.4585\n",
      "Epoch [500/450], Loss: 0.4578\n",
      "Epoch [500/500], Loss: 0.4557\n",
      "Epoch [500/550], Loss: 0.4540\n",
      "Epoch [500/600], Loss: 0.4550\n",
      "Epoch [500/650], Loss: 0.4536\n",
      "Epoch [500/700], Loss: 0.4533\n",
      "Epoch [500/750], Loss: 0.4518\n",
      "Epoch [500/800], Loss: 0.4513\n",
      "Epoch [500/850], Loss: 0.4509\n",
      "Epoch [500/900], Loss: 0.4501\n",
      "Epoch [500/950], Loss: 0.4496\n",
      "Epoch [500/50], Loss: 0.4485\n",
      "Epoch [500/100], Loss: 0.4474\n",
      "Epoch [500/150], Loss: 0.4469\n",
      "Epoch [500/200], Loss: 0.4462\n",
      "Epoch [500/250], Loss: 0.4465\n",
      "Epoch [500/300], Loss: 0.4443\n",
      "Epoch [500/350], Loss: 0.4444\n",
      "Epoch [500/400], Loss: 0.4428\n",
      "Epoch [500/450], Loss: 0.4428\n",
      "Epoch [500/500], Loss: 0.4443\n",
      "Epoch [500/550], Loss: 0.4503\n",
      "Epoch [500/600], Loss: 0.4439\n",
      "Epoch [500/650], Loss: 0.4445\n",
      "Epoch [500/700], Loss: 0.4431\n",
      "Epoch [500/750], Loss: 0.4438\n",
      "Epoch [500/800], Loss: 0.4460\n",
      "Epoch [500/850], Loss: 0.4425\n",
      "Epoch [500/900], Loss: 0.4396\n",
      "Epoch [500/950], Loss: 0.4412\n",
      "Epoch [500/50], Loss: 0.4382\n",
      "Epoch [500/100], Loss: 0.4403\n",
      "Epoch [500/150], Loss: 0.4373\n",
      "Epoch [500/200], Loss: 0.4385\n",
      "Epoch [500/250], Loss: 0.4368\n",
      "Epoch [500/300], Loss: 0.4364\n",
      "Epoch [500/350], Loss: 0.4365\n",
      "Epoch [500/400], Loss: 0.4351\n",
      "Epoch [500/450], Loss: 0.4352\n",
      "Epoch [500/500], Loss: 0.4352\n",
      "Epoch [500/550], Loss: 0.4334\n",
      "Epoch [500/600], Loss: 0.4337\n",
      "Epoch [500/650], Loss: 0.4333\n",
      "Epoch [500/700], Loss: 0.4324\n",
      "Epoch [500/750], Loss: 0.4320\n",
      "Epoch [500/800], Loss: 0.4322\n",
      "Epoch [500/850], Loss: 0.4314\n",
      "Epoch [500/900], Loss: 0.4307\n",
      "Epoch [500/950], Loss: 0.4302\n",
      "Epoch [500/50], Loss: 0.4299\n",
      "Epoch [500/100], Loss: 0.4299\n",
      "Epoch [500/150], Loss: 0.4305\n",
      "Epoch [500/200], Loss: 0.4319\n",
      "Epoch [500/250], Loss: 0.4360\n",
      "Epoch [500/300], Loss: 0.4387\n",
      "Epoch [500/350], Loss: 0.4405\n",
      "Epoch [500/400], Loss: 0.4329\n",
      "Epoch [500/450], Loss: 0.4291\n",
      "Epoch [500/500], Loss: 0.4324\n",
      "Epoch [500/550], Loss: 0.4360\n",
      "Epoch [500/600], Loss: 0.4302\n",
      "Epoch [500/650], Loss: 0.4282\n",
      "Epoch [500/700], Loss: 0.4305\n",
      "Epoch [500/750], Loss: 0.4321\n",
      "Epoch [500/800], Loss: 0.4302\n",
      "Epoch [500/850], Loss: 0.4273\n",
      "Epoch [500/900], Loss: 0.4269\n",
      "Epoch [500/950], Loss: 0.4280\n",
      "Epoch [500/50], Loss: 0.4294\n",
      "Epoch [500/100], Loss: 0.4303\n",
      "Epoch [500/150], Loss: 0.4293\n",
      "Epoch [500/200], Loss: 0.4280\n",
      "Epoch [500/250], Loss: 0.4271\n",
      "Epoch [500/300], Loss: 0.4256\n",
      "Epoch [500/350], Loss: 0.4252\n",
      "Epoch [500/400], Loss: 0.4250\n",
      "Epoch [500/450], Loss: 0.4248\n",
      "Epoch [500/500], Loss: 0.4258\n",
      "Epoch [500/550], Loss: 0.4287\n",
      "Epoch [500/600], Loss: 0.4375\n",
      "Epoch [500/650], Loss: 0.4574\n",
      "Epoch [500/700], Loss: 0.4883\n",
      "Epoch [500/750], Loss: 0.4530\n",
      "Epoch [500/800], Loss: 0.4460\n",
      "Epoch [500/850], Loss: 0.4694\n",
      "Epoch [500/900], Loss: 0.4426\n",
      "Epoch [500/950], Loss: 0.4535\n",
      "Epoch [500/50], Loss: 0.4409\n",
      "Epoch [500/100], Loss: 0.4470\n",
      "Epoch [500/150], Loss: 0.4368\n",
      "Epoch [500/200], Loss: 0.4423\n",
      "Epoch [500/250], Loss: 0.4388\n",
      "Epoch [500/300], Loss: 0.4371\n",
      "Epoch [500/350], Loss: 0.4403\n",
      "Epoch [500/400], Loss: 0.4349\n",
      "Epoch [500/450], Loss: 0.4408\n",
      "Epoch [500/500], Loss: 0.4346\n",
      "Epoch [500/550], Loss: 0.4353\n",
      "Epoch [500/600], Loss: 0.4352\n",
      "Epoch [500/650], Loss: 0.4327\n",
      "Epoch [500/700], Loss: 0.4340\n",
      "Epoch [500/750], Loss: 0.4319\n",
      "Epoch [500/800], Loss: 0.4323\n",
      "Epoch [500/850], Loss: 0.4314\n",
      "Epoch [500/900], Loss: 0.4307\n",
      "Epoch [500/950], Loss: 0.4309\n",
      "Epoch [500/50], Loss: 0.4295\n",
      "Epoch [500/100], Loss: 0.4306\n",
      "Epoch [500/150], Loss: 0.4297\n",
      "Epoch [500/200], Loss: 0.4294\n",
      "Epoch [500/250], Loss: 0.4277\n",
      "Epoch [500/300], Loss: 0.4287\n",
      "Epoch [500/350], Loss: 0.4282\n",
      "Epoch [500/400], Loss: 0.4268\n",
      "Epoch [500/450], Loss: 0.4265\n",
      "Epoch [500/500], Loss: 0.4263\n",
      "Epoch [500/550], Loss: 0.4268\n",
      "Epoch [500/600], Loss: 0.4250\n",
      "Epoch [500/650], Loss: 0.4250\n",
      "Epoch [500/700], Loss: 0.4241\n",
      "Epoch [500/750], Loss: 0.4250\n",
      "Epoch [500/800], Loss: 0.4250\n",
      "Epoch [500/850], Loss: 0.4254\n",
      "Epoch [500/900], Loss: 0.4278\n",
      "Epoch [500/950], Loss: 0.4286\n",
      "Epoch [500/50], Loss: 0.4341\n",
      "Epoch [500/100], Loss: 0.4483\n",
      "Epoch [500/150], Loss: 0.4717\n",
      "Epoch [500/200], Loss: 0.4545\n",
      "Epoch [500/250], Loss: 0.4264\n",
      "Epoch [500/300], Loss: 0.4438\n",
      "Epoch [500/350], Loss: 0.4407\n",
      "Epoch [500/400], Loss: 0.4282\n",
      "Epoch [500/450], Loss: 0.4387\n",
      "Epoch [500/500], Loss: 0.4292\n",
      "Epoch [500/550], Loss: 0.4313\n",
      "Epoch [500/600], Loss: 0.4339\n",
      "Epoch [500/650], Loss: 0.4267\n",
      "Epoch [500/700], Loss: 0.4340\n",
      "Epoch [500/750], Loss: 0.4279\n",
      "Epoch [500/800], Loss: 0.4286\n",
      "Epoch [500/850], Loss: 0.4306\n",
      "Epoch [500/900], Loss: 0.4258\n",
      "Epoch [500/950], Loss: 0.4292\n",
      "Epoch [500/50], Loss: 0.4275\n",
      "Epoch [500/100], Loss: 0.4250\n",
      "Epoch [500/150], Loss: 0.4283\n",
      "Epoch [500/200], Loss: 0.4252\n",
      "Epoch [500/250], Loss: 0.4246\n",
      "Epoch [500/300], Loss: 0.4261\n",
      "Epoch [500/350], Loss: 0.4247\n",
      "Epoch [500/400], Loss: 0.4232\n",
      "Epoch [500/450], Loss: 0.4236\n",
      "Epoch [500/500], Loss: 0.4252\n",
      "Epoch [500/550], Loss: 0.4256\n",
      "Epoch [500/600], Loss: 0.4225\n",
      "Epoch [500/650], Loss: 0.4220\n",
      "Epoch [500/700], Loss: 0.4223\n",
      "Epoch [500/750], Loss: 0.4230\n",
      "Epoch [500/800], Loss: 0.4243\n",
      "Epoch [500/850], Loss: 0.4237\n",
      "Epoch [500/900], Loss: 0.4230\n",
      "Epoch [500/950], Loss: 0.4228\n",
      "Epoch [500/50], Loss: 0.4232\n",
      "Epoch [500/100], Loss: 0.4227\n",
      "Epoch [500/150], Loss: 0.4255\n",
      "Epoch [500/200], Loss: 0.4310\n",
      "Epoch [500/250], Loss: 0.4402\n",
      "Epoch [500/300], Loss: 0.4468\n",
      "Epoch [500/350], Loss: 0.4512\n",
      "Epoch [500/400], Loss: 0.4242\n",
      "Epoch [500/450], Loss: 0.4342\n",
      "Epoch [500/500], Loss: 0.4439\n",
      "Epoch [500/550], Loss: 0.4378\n",
      "Epoch [500/600], Loss: 0.4319\n",
      "Epoch [500/650], Loss: 0.4347\n",
      "Epoch [500/700], Loss: 0.4373\n",
      "Epoch [500/750], Loss: 0.4258\n",
      "Epoch [500/800], Loss: 0.4364\n",
      "Epoch [500/850], Loss: 0.4281\n",
      "Epoch [500/900], Loss: 0.4304\n",
      "Epoch [500/950], Loss: 0.4293\n",
      "Epoch [500/50], Loss: 0.4283\n",
      "Epoch [500/100], Loss: 0.4258\n",
      "Epoch [500/150], Loss: 0.4286\n",
      "Epoch [500/200], Loss: 0.4252\n",
      "Epoch [500/250], Loss: 0.4273\n",
      "Epoch [500/300], Loss: 0.4253\n",
      "Epoch [500/350], Loss: 0.4309\n",
      "Epoch [500/400], Loss: 0.4342\n",
      "Epoch [500/450], Loss: 0.4382\n",
      "Epoch [500/500], Loss: 0.4264\n",
      "Epoch [500/550], Loss: 0.4253\n",
      "Epoch [500/600], Loss: 0.4299\n",
      "Epoch [500/650], Loss: 0.4252\n",
      "Epoch [500/700], Loss: 0.4230\n",
      "Epoch [500/750], Loss: 0.4270\n",
      "Epoch [500/800], Loss: 0.4245\n",
      "Epoch [500/850], Loss: 0.4214\n",
      "Epoch [500/900], Loss: 0.4244\n",
      "Epoch [500/950], Loss: 0.4238\n",
      "Epoch [500/50], Loss: 0.4218\n",
      "Epoch [500/100], Loss: 0.4202\n",
      "Epoch [500/150], Loss: 0.4222\n",
      "Epoch [500/200], Loss: 0.4219\n",
      "Epoch [500/250], Loss: 0.4204\n",
      "Epoch [500/300], Loss: 0.4193\n",
      "Epoch [500/350], Loss: 0.4186\n",
      "Epoch [500/400], Loss: 0.4197\n",
      "Epoch [500/450], Loss: 0.4209\n",
      "Epoch [500/500], Loss: 0.4226\n",
      "Epoch [500/550], Loss: 0.4251\n",
      "Epoch [500/600], Loss: 0.4303\n",
      "Epoch [500/650], Loss: 0.4330\n",
      "Epoch [500/700], Loss: 0.4350\n",
      "Epoch [500/750], Loss: 0.4311\n",
      "Epoch [500/800], Loss: 0.4229\n",
      "Epoch [500/850], Loss: 0.4184\n",
      "Epoch [500/900], Loss: 0.4210\n",
      "Epoch [500/950], Loss: 0.4267\n",
      "Epoch [500/50], Loss: 0.4272\n",
      "Epoch [500/100], Loss: 0.4251\n",
      "Epoch [500/150], Loss: 0.4206\n",
      "Epoch [500/200], Loss: 0.4176\n",
      "Epoch [500/250], Loss: 0.4181\n",
      "Epoch [500/300], Loss: 0.4212\n",
      "Epoch [500/350], Loss: 0.4236\n",
      "Epoch [500/400], Loss: 0.4236\n",
      "Epoch [500/450], Loss: 0.4233\n",
      "Epoch [500/500], Loss: 0.4199\n",
      "Epoch [500/550], Loss: 0.4176\n",
      "Epoch [500/600], Loss: 0.4164\n",
      "Epoch [500/650], Loss: 0.4162\n",
      "Epoch [500/700], Loss: 0.4167\n",
      "Epoch [500/750], Loss: 0.4180\n",
      "Epoch [500/800], Loss: 0.4225\n",
      "Epoch [500/850], Loss: 0.4330\n",
      "Epoch [500/900], Loss: 0.4575\n",
      "Epoch [500/950], Loss: 0.4615\n",
      "Epoch [500/50], Loss: 0.4402\n",
      "Epoch [500/100], Loss: 0.4206\n",
      "Epoch [500/150], Loss: 0.4428\n",
      "Epoch [500/200], Loss: 0.4368\n",
      "Epoch [500/250], Loss: 0.4238\n",
      "Epoch [500/300], Loss: 0.4398\n",
      "Epoch [500/350], Loss: 0.4260\n",
      "Epoch [500/400], Loss: 0.4277\n",
      "Epoch [500/450], Loss: 0.4256\n",
      "Epoch [500/500], Loss: 0.4297\n",
      "Epoch [500/550], Loss: 0.4216\n",
      "Epoch [500/600], Loss: 0.4289\n",
      "Epoch [500/650], Loss: 0.4217\n",
      "Epoch [500/700], Loss: 0.4251\n",
      "Epoch [500/750], Loss: 0.4229\n",
      "Epoch [500/800], Loss: 0.4228\n",
      "Epoch [500/850], Loss: 0.4219\n",
      "Epoch [500/900], Loss: 0.4220\n",
      "Epoch [500/950], Loss: 0.4223\n",
      "Epoch [500/50], Loss: 0.4193\n",
      "Epoch [500/100], Loss: 0.4227\n",
      "Epoch [500/150], Loss: 0.4191\n",
      "Epoch [500/200], Loss: 0.4203\n",
      "Epoch [500/250], Loss: 0.4190\n",
      "Epoch [500/300], Loss: 0.4182\n",
      "Epoch [500/350], Loss: 0.4196\n",
      "Epoch [500/400], Loss: 0.4171\n",
      "Epoch [500/450], Loss: 0.4178\n",
      "Epoch [500/500], Loss: 0.4176\n",
      "Epoch [500/550], Loss: 0.4157\n",
      "Epoch [500/600], Loss: 0.4169\n",
      "Epoch [500/650], Loss: 0.4169\n",
      "Epoch [500/700], Loss: 0.4148\n",
      "Epoch [500/750], Loss: 0.4152\n",
      "Epoch [500/800], Loss: 0.4173\n",
      "Epoch [500/850], Loss: 0.4197\n",
      "Epoch [500/900], Loss: 0.4260\n",
      "Epoch [500/950], Loss: 0.4386\n",
      "Epoch [500/50], Loss: 0.4802\n",
      "Epoch [500/100], Loss: 0.5135\n",
      "Epoch [500/150], Loss: 0.4640\n",
      "Epoch [500/200], Loss: 0.4721\n",
      "Epoch [500/250], Loss: 0.5046\n",
      "Epoch [500/300], Loss: 0.4436\n",
      "Epoch [500/350], Loss: 0.4755\n",
      "Epoch [500/400], Loss: 0.4633\n",
      "Epoch [500/450], Loss: 0.4475\n",
      "Epoch [500/500], Loss: 0.4551\n",
      "Epoch [500/550], Loss: 0.4556\n",
      "Epoch [500/600], Loss: 0.4469\n",
      "Epoch [500/650], Loss: 0.4566\n",
      "Epoch [500/700], Loss: 0.4573\n",
      "Epoch [500/750], Loss: 0.4477\n",
      "Epoch [500/800], Loss: 0.4481\n",
      "Epoch [500/850], Loss: 0.4496\n",
      "Epoch [500/900], Loss: 0.4444\n",
      "Epoch [500/950], Loss: 0.4479\n",
      "Epoch [500/50], Loss: 0.4418\n",
      "Epoch [500/100], Loss: 0.4440\n",
      "Epoch [500/150], Loss: 0.4444\n",
      "Epoch [500/200], Loss: 0.4398\n",
      "Epoch [500/250], Loss: 0.4417\n",
      "Epoch [500/300], Loss: 0.4398\n",
      "Epoch [500/350], Loss: 0.4406\n",
      "Epoch [500/400], Loss: 0.4377\n",
      "Epoch [500/450], Loss: 0.4376\n",
      "Epoch [500/500], Loss: 0.4373\n",
      "Epoch [500/550], Loss: 0.4356\n",
      "Epoch [500/600], Loss: 0.4351\n",
      "Epoch [500/650], Loss: 0.4345\n",
      "Epoch [500/700], Loss: 0.4344\n",
      "Epoch [500/750], Loss: 0.4327\n",
      "Epoch [500/800], Loss: 0.4325\n",
      "Epoch [500/850], Loss: 0.4316\n",
      "Epoch [500/900], Loss: 0.4309\n",
      "Epoch [500/950], Loss: 0.4304\n",
      "Epoch [500/50], Loss: 0.4301\n",
      "Epoch [500/100], Loss: 0.4289\n",
      "Epoch [500/150], Loss: 0.4286\n",
      "Epoch [500/200], Loss: 0.4279\n",
      "Epoch [500/250], Loss: 0.4272\n",
      "Epoch [500/300], Loss: 0.4267\n",
      "Epoch [500/350], Loss: 0.4261\n",
      "Epoch [500/400], Loss: 0.4256\n",
      "Epoch [500/450], Loss: 0.4251\n",
      "Epoch [500/500], Loss: 0.4244\n",
      "Epoch [500/550], Loss: 0.4240\n",
      "Epoch [500/600], Loss: 0.4233\n",
      "Epoch [500/650], Loss: 0.4229\n",
      "Epoch [500/700], Loss: 0.4223\n",
      "Epoch [500/750], Loss: 0.4218\n",
      "Epoch [500/800], Loss: 0.4214\n",
      "Epoch [500/850], Loss: 0.4209\n",
      "Epoch [500/900], Loss: 0.4204\n",
      "Epoch [500/950], Loss: 0.4199\n",
      "Epoch [500/50], Loss: 0.4195\n",
      "Epoch [500/100], Loss: 0.4190\n",
      "Epoch [500/150], Loss: 0.4186\n",
      "Epoch [500/200], Loss: 0.4183\n",
      "Epoch [500/250], Loss: 0.4181\n",
      "Epoch [500/300], Loss: 0.4187\n",
      "Epoch [500/350], Loss: 0.4224\n",
      "Epoch [500/400], Loss: 0.4321\n",
      "Epoch [500/450], Loss: 0.4466\n",
      "Epoch [500/500], Loss: 0.4532\n",
      "Epoch [500/550], Loss: 0.4302\n",
      "Epoch [500/600], Loss: 0.4204\n",
      "Epoch [500/650], Loss: 0.4352\n",
      "Epoch [500/700], Loss: 0.4310\n",
      "Epoch [500/750], Loss: 0.4191\n",
      "Epoch [500/800], Loss: 0.4304\n",
      "Epoch [500/850], Loss: 0.4301\n",
      "Epoch [500/900], Loss: 0.4196\n",
      "Epoch [500/950], Loss: 0.4232\n",
      "Epoch [500/50], Loss: 0.4279\n",
      "Epoch [500/100], Loss: 0.4196\n",
      "Epoch [500/150], Loss: 0.4206\n",
      "Epoch [500/200], Loss: 0.4236\n",
      "Epoch [500/250], Loss: 0.4201\n",
      "Epoch [500/300], Loss: 0.4180\n",
      "Epoch [500/350], Loss: 0.4216\n",
      "Epoch [500/400], Loss: 0.4194\n",
      "Epoch [500/450], Loss: 0.4171\n",
      "Epoch [500/500], Loss: 0.4184\n",
      "Epoch [500/550], Loss: 0.4192\n",
      "Epoch [500/600], Loss: 0.4174\n",
      "Epoch [500/650], Loss: 0.4158\n",
      "Epoch [500/700], Loss: 0.4167\n",
      "Epoch [500/750], Loss: 0.4175\n",
      "Epoch [500/800], Loss: 0.4177\n",
      "Epoch [500/850], Loss: 0.4171\n",
      "Epoch [500/900], Loss: 0.4155\n",
      "Epoch [500/950], Loss: 0.4147\n",
      "Epoch [500/50], Loss: 0.4139\n",
      "Epoch [500/100], Loss: 0.4136\n",
      "Epoch [500/150], Loss: 0.4139\n",
      "Epoch [500/200], Loss: 0.4151\n",
      "Epoch [500/250], Loss: 0.4201\n",
      "Epoch [500/300], Loss: 0.4354\n",
      "Epoch [500/350], Loss: 0.4713\n",
      "Epoch [500/400], Loss: 0.4706\n",
      "Epoch [500/450], Loss: 0.4237\n",
      "Epoch [500/500], Loss: 0.4331\n",
      "Epoch [500/550], Loss: 0.4462\n",
      "Epoch [500/600], Loss: 0.4263\n",
      "Epoch [500/650], Loss: 0.4345\n",
      "Epoch [500/700], Loss: 0.4357\n",
      "Epoch [500/750], Loss: 0.4208\n",
      "Epoch [500/800], Loss: 0.4341\n",
      "Epoch [500/850], Loss: 0.4201\n",
      "Epoch [500/900], Loss: 0.4275\n",
      "Epoch [500/950], Loss: 0.4267\n",
      "Epoch [500/50], Loss: 0.4233\n",
      "Epoch [500/100], Loss: 0.4227\n",
      "Epoch [500/150], Loss: 0.4251\n",
      "Epoch [500/200], Loss: 0.4189\n",
      "Epoch [500/250], Loss: 0.4242\n",
      "Epoch [500/300], Loss: 0.4185\n",
      "Epoch [500/350], Loss: 0.4217\n",
      "Epoch [500/400], Loss: 0.4198\n",
      "Epoch [500/450], Loss: 0.4193\n",
      "Epoch [500/500], Loss: 0.4288\n",
      "Epoch [500/550], Loss: 0.4484\n",
      "Epoch [500/600], Loss: 0.4281\n",
      "Epoch [500/650], Loss: 0.4268\n",
      "Epoch [500/700], Loss: 0.4431\n",
      "Epoch [500/750], Loss: 0.4222\n",
      "Epoch [500/800], Loss: 0.4333\n",
      "Epoch [500/850], Loss: 0.4257\n",
      "Epoch [500/900], Loss: 0.4226\n",
      "Epoch [500/950], Loss: 0.4292\n",
      "Epoch [500/50], Loss: 0.4217\n",
      "Epoch [500/100], Loss: 0.4244\n",
      "Epoch [500/150], Loss: 0.4249\n",
      "Epoch [500/200], Loss: 0.4180\n",
      "Epoch [500/250], Loss: 0.4247\n",
      "Epoch [500/300], Loss: 0.4181\n",
      "Epoch [500/350], Loss: 0.4202\n",
      "Epoch [500/400], Loss: 0.4206\n",
      "Epoch [500/450], Loss: 0.4179\n",
      "Epoch [500/500], Loss: 0.4186\n",
      "Epoch [500/550], Loss: 0.4199\n",
      "Epoch [500/600], Loss: 0.4171\n",
      "Epoch [500/650], Loss: 0.4162\n",
      "Epoch [500/700], Loss: 0.4193\n",
      "Epoch [500/750], Loss: 0.4155\n",
      "Epoch [500/800], Loss: 0.4158\n",
      "Epoch [500/850], Loss: 0.4154\n",
      "Epoch [500/900], Loss: 0.4165\n",
      "Epoch [500/950], Loss: 0.4152\n",
      "Epoch [500/50], Loss: 0.4130\n",
      "Epoch [500/100], Loss: 0.4144\n",
      "Epoch [500/150], Loss: 0.4139\n",
      "Epoch [500/200], Loss: 0.4148\n",
      "Epoch [500/250], Loss: 0.4146\n",
      "Epoch [500/300], Loss: 0.4134\n",
      "Epoch [500/350], Loss: 0.4136\n",
      "Epoch [500/400], Loss: 0.4134\n",
      "Epoch [500/450], Loss: 0.4129\n",
      "Epoch [500/500], Loss: 0.4145\n",
      "Epoch [500/550], Loss: 0.4172\n",
      "Epoch [500/600], Loss: 0.4249\n",
      "Epoch [500/650], Loss: 0.4378\n",
      "Epoch [500/700], Loss: 0.4504\n",
      "Epoch [500/750], Loss: 0.4421\n",
      "Epoch [500/800], Loss: 0.4189\n",
      "Epoch [500/850], Loss: 0.4215\n",
      "Epoch [500/900], Loss: 0.4350\n",
      "Epoch [500/950], Loss: 0.4271\n",
      "Epoch [500/50], Loss: 0.4156\n",
      "Epoch [500/100], Loss: 0.4358\n",
      "Epoch [500/150], Loss: 0.4298\n",
      "Epoch [500/200], Loss: 0.4189\n",
      "Epoch [500/250], Loss: 0.4275\n",
      "Epoch [500/300], Loss: 0.4234\n",
      "Epoch [500/350], Loss: 0.4221\n",
      "Epoch [500/400], Loss: 0.4174\n",
      "Epoch [500/450], Loss: 0.4250\n",
      "Epoch [500/500], Loss: 0.4148\n",
      "Epoch [500/550], Loss: 0.4213\n",
      "Epoch [500/600], Loss: 0.4161\n",
      "Epoch [500/650], Loss: 0.4162\n",
      "Epoch [500/700], Loss: 0.4175\n",
      "Epoch [500/750], Loss: 0.4214\n",
      "Epoch [500/800], Loss: 0.4423\n",
      "Epoch [500/850], Loss: 0.4355\n",
      "Epoch [500/900], Loss: 0.4173\n",
      "Epoch [500/950], Loss: 0.4278\n",
      "Epoch [500/50], Loss: 0.4291\n",
      "Epoch [500/100], Loss: 0.4176\n",
      "Epoch [500/150], Loss: 0.4236\n",
      "Epoch [500/200], Loss: 0.4220\n",
      "Epoch [500/250], Loss: 0.4147\n",
      "Epoch [500/300], Loss: 0.4216\n",
      "Epoch [500/350], Loss: 0.4167\n",
      "Epoch [500/400], Loss: 0.4163\n",
      "Epoch [500/450], Loss: 0.4179\n",
      "Epoch [500/500], Loss: 0.4181\n",
      "Epoch [500/550], Loss: 0.4134\n",
      "Epoch [500/600], Loss: 0.4178\n",
      "Epoch [500/650], Loss: 0.4164\n",
      "Epoch [500/700], Loss: 0.4133\n",
      "Epoch [500/750], Loss: 0.4148\n",
      "Epoch [500/800], Loss: 0.4154\n",
      "Epoch [500/850], Loss: 0.4159\n",
      "Epoch [500/900], Loss: 0.4115\n",
      "Epoch [500/950], Loss: 0.4131\n",
      "Epoch [500/50], Loss: 0.4155\n",
      "Epoch [500/100], Loss: 0.4144\n",
      "Epoch [500/150], Loss: 0.4138\n",
      "Epoch [500/200], Loss: 0.4109\n",
      "Epoch [500/250], Loss: 0.4103\n",
      "Epoch [500/300], Loss: 0.4113\n",
      "Epoch [500/350], Loss: 0.4114\n",
      "Epoch [500/400], Loss: 0.4138\n",
      "Epoch [500/450], Loss: 0.4195\n",
      "Epoch [500/500], Loss: 0.4319\n",
      "Epoch [500/550], Loss: 0.4355\n",
      "Epoch [500/600], Loss: 0.4313\n",
      "Epoch [500/650], Loss: 0.4179\n",
      "Epoch [500/700], Loss: 0.4113\n",
      "Epoch [500/750], Loss: 0.4179\n",
      "Epoch [500/800], Loss: 0.4261\n",
      "Epoch [500/850], Loss: 0.4323\n",
      "Epoch [500/900], Loss: 0.4157\n",
      "Epoch [500/950], Loss: 0.4125\n",
      "Epoch [500/50], Loss: 0.4205\n",
      "Epoch [500/100], Loss: 0.4214\n",
      "Epoch [500/150], Loss: 0.4162\n",
      "Epoch [500/200], Loss: 0.4109\n",
      "Epoch [500/250], Loss: 0.4146\n",
      "Epoch [500/300], Loss: 0.4171\n",
      "Epoch [500/350], Loss: 0.4134\n",
      "Epoch [500/400], Loss: 0.4116\n",
      "Epoch [500/450], Loss: 0.4115\n",
      "Epoch [500/500], Loss: 0.4132\n",
      "Epoch [500/550], Loss: 0.4163\n",
      "Epoch [500/600], Loss: 0.4127\n",
      "Epoch [500/650], Loss: 0.4105\n",
      "Epoch [500/700], Loss: 0.4102\n",
      "Epoch [500/750], Loss: 0.4099\n",
      "Epoch [500/800], Loss: 0.4112\n",
      "Epoch [500/850], Loss: 0.4135\n",
      "Epoch [500/900], Loss: 0.4150\n",
      "Epoch [500/950], Loss: 0.4167\n",
      "Epoch [500/50], Loss: 0.4214\n",
      "Epoch [500/100], Loss: 0.4191\n",
      "Epoch [500/150], Loss: 0.4180\n",
      "Epoch [500/200], Loss: 0.4152\n",
      "Epoch [500/250], Loss: 0.4109\n",
      "Epoch [500/300], Loss: 0.4084\n",
      "Epoch [500/350], Loss: 0.4087\n",
      "Epoch [500/400], Loss: 0.4101\n",
      "Epoch [500/450], Loss: 0.4127\n",
      "Epoch [500/500], Loss: 0.4190\n",
      "Epoch [500/550], Loss: 0.4271\n",
      "Epoch [500/600], Loss: 0.4436\n",
      "Epoch [500/650], Loss: 0.4353\n",
      "Epoch [500/700], Loss: 0.4173\n",
      "Epoch [500/750], Loss: 0.4111\n",
      "Epoch [500/800], Loss: 0.4212\n",
      "Epoch [500/850], Loss: 0.4227\n",
      "Epoch [500/900], Loss: 0.4133\n",
      "Epoch [500/950], Loss: 0.4100\n",
      "Epoch [500/50], Loss: 0.4152\n",
      "Epoch [500/100], Loss: 0.4194\n",
      "Epoch [500/150], Loss: 0.4184\n",
      "Epoch [500/200], Loss: 0.4108\n",
      "Epoch [500/250], Loss: 0.4098\n",
      "Epoch [500/300], Loss: 0.4145\n",
      "Epoch [500/350], Loss: 0.4155\n",
      "Epoch [500/400], Loss: 0.4131\n",
      "Epoch [500/450], Loss: 0.4096\n",
      "Epoch [500/500], Loss: 0.4092\n",
      "Epoch [500/550], Loss: 0.4115\n",
      "Epoch [500/600], Loss: 0.4136\n",
      "Epoch [500/650], Loss: 0.4138\n",
      "Epoch [500/700], Loss: 0.4120\n",
      "Epoch [500/750], Loss: 0.4099\n",
      "Epoch [500/800], Loss: 0.4083\n",
      "Epoch [500/850], Loss: 0.4076\n",
      "Epoch [500/900], Loss: 0.4074\n",
      "Epoch [500/950], Loss: 0.4080\n",
      "Epoch [500/50], Loss: 0.4109\n",
      "Epoch [500/100], Loss: 0.4196\n",
      "Epoch [500/150], Loss: 0.4437\n",
      "Epoch [500/200], Loss: 0.4443\n",
      "Epoch [500/250], Loss: 0.4328\n",
      "Epoch [500/300], Loss: 0.4149\n",
      "Epoch [500/350], Loss: 0.4129\n",
      "Epoch [500/400], Loss: 0.4260\n",
      "Epoch [500/450], Loss: 0.4221\n",
      "Epoch [500/500], Loss: 0.4112\n",
      "Epoch [500/550], Loss: 0.4150\n",
      "Epoch [500/600], Loss: 0.4212\n",
      "Epoch [500/650], Loss: 0.4209\n",
      "Epoch [500/700], Loss: 0.4119\n",
      "Epoch [500/750], Loss: 0.4118\n",
      "Epoch [500/800], Loss: 0.4179\n",
      "Epoch [500/850], Loss: 0.4140\n",
      "Epoch [500/900], Loss: 0.4092\n",
      "Epoch [500/950], Loss: 0.4098\n",
      "Epoch [500/50], Loss: 0.4135\n",
      "Epoch [500/100], Loss: 0.4164\n",
      "Epoch [500/150], Loss: 0.4131\n",
      "Epoch [500/200], Loss: 0.4095\n",
      "Epoch [500/250], Loss: 0.4091\n",
      "Epoch [500/300], Loss: 0.4121\n",
      "Epoch [500/350], Loss: 0.4143\n",
      "Epoch [500/400], Loss: 0.4128\n",
      "Epoch [500/450], Loss: 0.4095\n",
      "Epoch [500/500], Loss: 0.4079\n",
      "Epoch [500/550], Loss: 0.4079\n",
      "Epoch [500/600], Loss: 0.4083\n",
      "Epoch [500/650], Loss: 0.4102\n",
      "Epoch [500/700], Loss: 0.4146\n",
      "Epoch [500/750], Loss: 0.4169\n",
      "Epoch [500/800], Loss: 0.4238\n",
      "Epoch [500/850], Loss: 0.4236\n",
      "Epoch [500/900], Loss: 0.4212\n",
      "Epoch [500/950], Loss: 0.4146\n",
      "Epoch [500/50], Loss: 0.4076\n",
      "Epoch [500/100], Loss: 0.4082\n",
      "Epoch [500/150], Loss: 0.4137\n",
      "Epoch [500/200], Loss: 0.4177\n",
      "Epoch [500/250], Loss: 0.4200\n",
      "Epoch [500/300], Loss: 0.4237\n",
      "Epoch [500/350], Loss: 0.4132\n",
      "Epoch [500/400], Loss: 0.4073\n",
      "Epoch [500/450], Loss: 0.4076\n",
      "Epoch [500/500], Loss: 0.4113\n",
      "Epoch [500/550], Loss: 0.4155\n",
      "Epoch [500/600], Loss: 0.4145\n",
      "Epoch [500/650], Loss: 0.4132\n",
      "Epoch [500/700], Loss: 0.4106\n",
      "Epoch [500/750], Loss: 0.4070\n",
      "Epoch [500/800], Loss: 0.4064\n",
      "Epoch [500/850], Loss: 0.4088\n",
      "Epoch [500/900], Loss: 0.4113\n",
      "Epoch [500/950], Loss: 0.4136\n",
      "Epoch [500/50], Loss: 0.4178\n",
      "Epoch [500/100], Loss: 0.4201\n",
      "Epoch [500/150], Loss: 0.4261\n",
      "Epoch [500/200], Loss: 0.4151\n",
      "Epoch [500/250], Loss: 0.4091\n",
      "Epoch [500/300], Loss: 0.4082\n",
      "Epoch [500/350], Loss: 0.4094\n",
      "Epoch [500/400], Loss: 0.4126\n",
      "Epoch [500/450], Loss: 0.4159\n",
      "Epoch [500/500], Loss: 0.4176\n",
      "Epoch [500/550], Loss: 0.4160\n",
      "Epoch [500/600], Loss: 0.4100\n",
      "Epoch [500/650], Loss: 0.4074\n",
      "Epoch [500/700], Loss: 0.4083\n",
      "Epoch [500/750], Loss: 0.4082\n",
      "Epoch [500/800], Loss: 0.4081\n",
      "Epoch [500/850], Loss: 0.4106\n",
      "Epoch [500/900], Loss: 0.4134\n",
      "Epoch [500/950], Loss: 0.4198\n",
      "Epoch [500/50], Loss: 0.4154\n",
      "Epoch [500/100], Loss: 0.4160\n",
      "Epoch [500/150], Loss: 0.4164\n",
      "Epoch [500/200], Loss: 0.4115\n",
      "Epoch [500/250], Loss: 0.4067\n",
      "Epoch [500/300], Loss: 0.4063\n",
      "Epoch [500/350], Loss: 0.4082\n",
      "Epoch [500/400], Loss: 0.4092\n",
      "Epoch [500/450], Loss: 0.4122\n",
      "Epoch [500/500], Loss: 0.4259\n",
      "Epoch [500/550], Loss: 0.4583\n",
      "Epoch [500/600], Loss: 0.4340\n",
      "Epoch [500/650], Loss: 0.4132\n",
      "Epoch [500/700], Loss: 0.4138\n",
      "Epoch [500/750], Loss: 0.4229\n",
      "Epoch [500/800], Loss: 0.4162\n",
      "Epoch [500/850], Loss: 0.4078\n",
      "Epoch [500/900], Loss: 0.4140\n",
      "Epoch [500/950], Loss: 0.4180\n",
      "Epoch [500/50], Loss: 0.4110\n",
      "Epoch [500/100], Loss: 0.4075\n",
      "Epoch [500/150], Loss: 0.4124\n",
      "Epoch [500/200], Loss: 0.4145\n",
      "Epoch [500/250], Loss: 0.4108\n",
      "Epoch [500/300], Loss: 0.4079\n",
      "Epoch [500/350], Loss: 0.4091\n",
      "Epoch [500/400], Loss: 0.4105\n",
      "Epoch [500/450], Loss: 0.4101\n",
      "Epoch [500/500], Loss: 0.4090\n",
      "Epoch [500/550], Loss: 0.4062\n",
      "Epoch [500/600], Loss: 0.4067\n",
      "Epoch [500/650], Loss: 0.4095\n",
      "Epoch [500/700], Loss: 0.4097\n",
      "Epoch [500/750], Loss: 0.4108\n",
      "Epoch [500/800], Loss: 0.4108\n",
      "Epoch [500/850], Loss: 0.4113\n",
      "Epoch [500/900], Loss: 0.4106\n",
      "Epoch [500/950], Loss: 0.4084\n",
      "Epoch [500/50], Loss: 0.4066\n",
      "Epoch [500/100], Loss: 0.4064\n",
      "Epoch [500/150], Loss: 0.4062\n",
      "Epoch [500/200], Loss: 0.4063\n",
      "Epoch [500/250], Loss: 0.4055\n",
      "Epoch [500/300], Loss: 0.4060\n",
      "Epoch [500/350], Loss: 0.4087\n",
      "Epoch [500/400], Loss: 0.4196\n",
      "Epoch [500/450], Loss: 0.4438\n",
      "Epoch [500/500], Loss: 0.4878\n",
      "Epoch [500/550], Loss: 0.4424\n",
      "Epoch [500/600], Loss: 0.4227\n",
      "Epoch [500/650], Loss: 0.4812\n",
      "Epoch [500/700], Loss: 0.4489\n",
      "Epoch [500/750], Loss: 0.4443\n",
      "Epoch [500/800], Loss: 0.4727\n",
      "Epoch [500/850], Loss: 0.4280\n",
      "Epoch [500/900], Loss: 0.4524\n",
      "Epoch [500/950], Loss: 0.4241\n",
      "Epoch [500/50], Loss: 0.4493\n",
      "Epoch [500/100], Loss: 0.4212\n",
      "Epoch [500/150], Loss: 0.4404\n",
      "Epoch [500/200], Loss: 0.4245\n",
      "Epoch [500/250], Loss: 0.4325\n",
      "Epoch [500/300], Loss: 0.4278\n",
      "Epoch [500/350], Loss: 0.4249\n",
      "Epoch [500/400], Loss: 0.4309\n",
      "Epoch [500/450], Loss: 0.4202\n",
      "Epoch [500/500], Loss: 0.4294\n",
      "Epoch [500/550], Loss: 0.4206\n",
      "Epoch [500/600], Loss: 0.4260\n",
      "Epoch [500/650], Loss: 0.4208\n",
      "Epoch [500/700], Loss: 0.4208\n",
      "Epoch [500/750], Loss: 0.4208\n",
      "Epoch [500/800], Loss: 0.4186\n",
      "Epoch [500/850], Loss: 0.4195\n",
      "Epoch [500/900], Loss: 0.4178\n",
      "Epoch [500/950], Loss: 0.4175\n",
      "Epoch [500/50], Loss: 0.4165\n",
      "Epoch [500/100], Loss: 0.4158\n",
      "Epoch [500/150], Loss: 0.4153\n",
      "Epoch [500/200], Loss: 0.4150\n",
      "Epoch [500/250], Loss: 0.4131\n",
      "Epoch [500/300], Loss: 0.4139\n",
      "Epoch [500/350], Loss: 0.4119\n",
      "Epoch [500/400], Loss: 0.4119\n",
      "Epoch [500/450], Loss: 0.4110\n",
      "Epoch [500/500], Loss: 0.4107\n",
      "Epoch [500/550], Loss: 0.4097\n",
      "Epoch [500/600], Loss: 0.4099\n",
      "Epoch [500/650], Loss: 0.4088\n",
      "Epoch [500/700], Loss: 0.4084\n",
      "Epoch [500/750], Loss: 0.4082\n",
      "Epoch [500/800], Loss: 0.4075\n",
      "Epoch [500/850], Loss: 0.4074\n",
      "Epoch [500/900], Loss: 0.4066\n",
      "Epoch [500/950], Loss: 0.4061\n",
      "Epoch [500/50], Loss: 0.4061\n",
      "Epoch [500/100], Loss: 0.4057\n",
      "Epoch [500/150], Loss: 0.4056\n",
      "Epoch [500/200], Loss: 0.4064\n",
      "Epoch [500/250], Loss: 0.4082\n",
      "Epoch [500/300], Loss: 0.4123\n",
      "Epoch [500/350], Loss: 0.4255\n",
      "Epoch [500/400], Loss: 0.4255\n",
      "Epoch [500/450], Loss: 0.4356\n",
      "Epoch [500/500], Loss: 0.4166\n",
      "Epoch [500/550], Loss: 0.4089\n",
      "Epoch [500/600], Loss: 0.4146\n",
      "Epoch [500/650], Loss: 0.4181\n",
      "Epoch [500/700], Loss: 0.4138\n",
      "Epoch [500/750], Loss: 0.4060\n",
      "Epoch [500/800], Loss: 0.4078\n",
      "Epoch [500/850], Loss: 0.4143\n",
      "Epoch [500/900], Loss: 0.4135\n",
      "Epoch [500/950], Loss: 0.4086\n",
      "Epoch [500/50], Loss: 0.4067\n",
      "Epoch [500/100], Loss: 0.4073\n",
      "Epoch [500/150], Loss: 0.4082\n",
      "Epoch [500/200], Loss: 0.4097\n",
      "Epoch [500/250], Loss: 0.4109\n",
      "Epoch [500/300], Loss: 0.4057\n",
      "Epoch [500/350], Loss: 0.4049\n",
      "Epoch [500/400], Loss: 0.4070\n",
      "Epoch [500/450], Loss: 0.4066\n",
      "Epoch [500/500], Loss: 0.4072\n",
      "Epoch [500/550], Loss: 0.4091\n",
      "Epoch [500/600], Loss: 0.4101\n",
      "Epoch [500/650], Loss: 0.4093\n",
      "Epoch [500/700], Loss: 0.4089\n",
      "Epoch [500/750], Loss: 0.4086\n",
      "Epoch [500/800], Loss: 0.4096\n",
      "Epoch [500/850], Loss: 0.4059\n",
      "Epoch [500/900], Loss: 0.4046\n",
      "Epoch [500/950], Loss: 0.4052\n",
      "Epoch [500/50], Loss: 0.4054\n",
      "Epoch [500/100], Loss: 0.4041\n",
      "Epoch [500/150], Loss: 0.4029\n",
      "Epoch [500/200], Loss: 0.4033\n",
      "Epoch [500/250], Loss: 0.4053\n",
      "Epoch [500/300], Loss: 0.4076\n",
      "Epoch [500/350], Loss: 0.4170\n",
      "Epoch [500/400], Loss: 0.4281\n",
      "Epoch [500/450], Loss: 0.4696\n",
      "Epoch [500/500], Loss: 0.4720\n",
      "Epoch [500/550], Loss: 0.4114\n",
      "Epoch [500/600], Loss: 0.4352\n",
      "Epoch [500/650], Loss: 0.4414\n",
      "Epoch [500/700], Loss: 0.4263\n",
      "Epoch [500/750], Loss: 0.4310\n",
      "Epoch [500/800], Loss: 0.4446\n",
      "Epoch [500/850], Loss: 0.4529\n",
      "Epoch [500/900], Loss: 0.4399\n",
      "Epoch [500/950], Loss: 0.4334\n",
      "Epoch [500/50], Loss: 0.4372\n",
      "Epoch [500/100], Loss: 0.4250\n",
      "Epoch [500/150], Loss: 0.4372\n",
      "Epoch [500/200], Loss: 0.4230\n",
      "Epoch [500/250], Loss: 0.4281\n",
      "Epoch [500/300], Loss: 0.4288\n",
      "Epoch [500/350], Loss: 0.4209\n",
      "Epoch [500/400], Loss: 0.4254\n",
      "Epoch [500/450], Loss: 0.4198\n",
      "Epoch [500/500], Loss: 0.4209\n",
      "Epoch [500/550], Loss: 0.4205\n",
      "Epoch [500/600], Loss: 0.4197\n",
      "Epoch [500/650], Loss: 0.4186\n",
      "Epoch [500/700], Loss: 0.4169\n",
      "Epoch [500/750], Loss: 0.4178\n",
      "Epoch [500/800], Loss: 0.4156\n",
      "Epoch [500/850], Loss: 0.4166\n",
      "Epoch [500/900], Loss: 0.4145\n",
      "Epoch [500/950], Loss: 0.4146\n",
      "Epoch [500/50], Loss: 0.4138\n",
      "Epoch [500/100], Loss: 0.4131\n",
      "Epoch [500/150], Loss: 0.4125\n",
      "Epoch [500/200], Loss: 0.4116\n",
      "Epoch [500/250], Loss: 0.4115\n",
      "Epoch [500/300], Loss: 0.4107\n",
      "Epoch [500/350], Loss: 0.4100\n",
      "Epoch [500/400], Loss: 0.4094\n",
      "Epoch [500/450], Loss: 0.4091\n",
      "Epoch [500/500], Loss: 0.4084\n",
      "Epoch [500/550], Loss: 0.4077\n",
      "Epoch [500/600], Loss: 0.4076\n",
      "Epoch [500/650], Loss: 0.4068\n",
      "Epoch [500/700], Loss: 0.4066\n",
      "Epoch [500/750], Loss: 0.4058\n",
      "Epoch [500/800], Loss: 0.4056\n",
      "Epoch [500/850], Loss: 0.4053\n",
      "Epoch [500/900], Loss: 0.4049\n",
      "Epoch [500/950], Loss: 0.4052\n",
      "Epoch [500/50], Loss: 0.4060\n",
      "Epoch [500/100], Loss: 0.4079\n",
      "Epoch [500/150], Loss: 0.4119\n",
      "Epoch [500/200], Loss: 0.4198\n",
      "Epoch [500/250], Loss: 0.4233\n",
      "Epoch [500/300], Loss: 0.4254\n",
      "Epoch [500/350], Loss: 0.4181\n",
      "Epoch [500/400], Loss: 0.4077\n",
      "Epoch [500/450], Loss: 0.4042\n",
      "Epoch [500/500], Loss: 0.4085\n",
      "Epoch [500/550], Loss: 0.4141\n",
      "Epoch [500/600], Loss: 0.4130\n",
      "Epoch [500/650], Loss: 0.4099\n",
      "Epoch [500/700], Loss: 0.4049\n",
      "Epoch [500/750], Loss: 0.4033\n",
      "Epoch [500/800], Loss: 0.4047\n",
      "Epoch [500/850], Loss: 0.4074\n",
      "Epoch [500/900], Loss: 0.4101\n",
      "Epoch [500/950], Loss: 0.4104\n",
      "Epoch [500/50], Loss: 0.4095\n",
      "Epoch [500/100], Loss: 0.4065\n",
      "Epoch [500/150], Loss: 0.4042\n",
      "Epoch [500/200], Loss: 0.4024\n",
      "Epoch [500/250], Loss: 0.4023\n",
      "Epoch [500/300], Loss: 0.4036\n",
      "Epoch [500/350], Loss: 0.4056\n",
      "Epoch [500/400], Loss: 0.4105\n",
      "Epoch [500/450], Loss: 0.4174\n",
      "Epoch [500/500], Loss: 0.4294\n",
      "Epoch [500/550], Loss: 0.4306\n",
      "Epoch [500/600], Loss: 0.4214\n",
      "Epoch [500/650], Loss: 0.4054\n",
      "Epoch [500/700], Loss: 0.4075\n",
      "Epoch [500/750], Loss: 0.4183\n",
      "Epoch [500/800], Loss: 0.4134\n",
      "Epoch [500/850], Loss: 0.4044\n",
      "Epoch [500/900], Loss: 0.4043\n",
      "Epoch [500/950], Loss: 0.4107\n",
      "Epoch [500/50], Loss: 0.4139\n",
      "Epoch [500/100], Loss: 0.4085\n",
      "Epoch [500/150], Loss: 0.4032\n",
      "Epoch [500/200], Loss: 0.4040\n",
      "Epoch [500/250], Loss: 0.4080\n",
      "Epoch [500/300], Loss: 0.4093\n",
      "Epoch [500/350], Loss: 0.4060\n",
      "Epoch [500/400], Loss: 0.4030\n",
      "Epoch [500/450], Loss: 0.4026\n",
      "Epoch [500/500], Loss: 0.4044\n",
      "Epoch [500/550], Loss: 0.4068\n",
      "Epoch [500/600], Loss: 0.4076\n",
      "Epoch [500/650], Loss: 0.4087\n",
      "Epoch [500/700], Loss: 0.4065\n",
      "Epoch [500/750], Loss: 0.4049\n",
      "Epoch [500/800], Loss: 0.4031\n",
      "Epoch [500/850], Loss: 0.4020\n",
      "Epoch [500/900], Loss: 0.4012\n",
      "Epoch [500/950], Loss: 0.4008\n",
      "Epoch [500/50], Loss: 0.4007\n",
      "Epoch [500/100], Loss: 0.4012\n",
      "Epoch [500/150], Loss: 0.4029\n",
      "Epoch [500/200], Loss: 0.4079\n",
      "Epoch [500/250], Loss: 0.4236\n",
      "Epoch [500/300], Loss: 0.4486\n",
      "Epoch [500/350], Loss: 0.4903\n",
      "Epoch [500/400], Loss: 0.4268\n",
      "Epoch [500/450], Loss: 0.4586\n",
      "Epoch [500/500], Loss: 0.4955\n",
      "Epoch [500/550], Loss: 0.4906\n",
      "Epoch [500/600], Loss: 0.4293\n",
      "Epoch [500/650], Loss: 0.5059\n",
      "Epoch [500/700], Loss: 0.4260\n",
      "Epoch [500/750], Loss: 0.4439\n",
      "Epoch [500/800], Loss: 0.4560\n",
      "Epoch [500/850], Loss: 0.4396\n",
      "Epoch [500/900], Loss: 0.4309\n",
      "Epoch [500/950], Loss: 0.4445\n",
      "Epoch [500/50], Loss: 0.4410\n",
      "Epoch [500/100], Loss: 0.4353\n",
      "Epoch [500/150], Loss: 0.4365\n",
      "Epoch [500/200], Loss: 0.4353\n",
      "Epoch [500/250], Loss: 0.4330\n",
      "Epoch [500/300], Loss: 0.4322\n",
      "Epoch [500/350], Loss: 0.4298\n",
      "Epoch [500/400], Loss: 0.4332\n",
      "Epoch [500/450], Loss: 0.4284\n",
      "Epoch [500/500], Loss: 0.4301\n",
      "Epoch [500/550], Loss: 0.4270\n",
      "Epoch [500/600], Loss: 0.4292\n",
      "Epoch [500/650], Loss: 0.4261\n",
      "Epoch [500/700], Loss: 0.4266\n",
      "Epoch [500/750], Loss: 0.4257\n",
      "Epoch [500/800], Loss: 0.4252\n",
      "Epoch [500/850], Loss: 0.4238\n",
      "Epoch [500/900], Loss: 0.4234\n",
      "Epoch [500/950], Loss: 0.4228\n",
      "Epoch [500/50], Loss: 0.4216\n",
      "Epoch [500/100], Loss: 0.4210\n",
      "Epoch [500/150], Loss: 0.4206\n",
      "Epoch [500/200], Loss: 0.4194\n",
      "Epoch [500/250], Loss: 0.4190\n",
      "Epoch [500/300], Loss: 0.4181\n",
      "Epoch [500/350], Loss: 0.4178\n",
      "Epoch [500/400], Loss: 0.4165\n",
      "Epoch [500/450], Loss: 0.4166\n",
      "Epoch [500/500], Loss: 0.4152\n",
      "Epoch [500/550], Loss: 0.4148\n",
      "Epoch [500/600], Loss: 0.4145\n",
      "Epoch [500/650], Loss: 0.4134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hidden_size4 \u001b[38;5;129;01min\u001b[39;00m hidden_layer_sizes4:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m num_epochs \u001b[38;5;129;01min\u001b[39;00m num_epochs_list:\n\u001b[1;32m----> 9\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_train\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# Обратный проход и оптимизация\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[99], line 26\u001b[0m, in \u001b[0;36mMoreComplexClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(x)\n\u001b[1;32m---> 26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(x)\n\u001b[0;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_auc = 0.0\n",
    "best_hidden_size = None\n",
    "best_num_epochs = None\n",
    "for hidden_size1 in hidden_layer_sizes1:\n",
    "    for hidden_size2 in hidden_layer_sizes2:\n",
    "        for hidden_size3 in hidden_layer_sizes3:\n",
    "            for hidden_size4 in hidden_layer_sizes4:\n",
    "                for num_epochs in num_epochs_list:\n",
    "                    outputs = model(X_train)\n",
    "                    loss = criterion(outputs, y_train.view(-1, 1))\n",
    "                \n",
    "                    # Обратный проход и оптимизация\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                    # Выводим значение функции потерь на каждой эпохе\n",
    "                    if (epoch + 1) % 10 == 0:\n",
    "                        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "                # Оценка точности с использованием AUC на тестовом наборе\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_pred_probs_test = model(X_test)\n",
    "                    y_pred_probs_train = model(X_train)\n",
    "                    y_pred_probs_test = y_pred_probs_test.numpy().flatten()\n",
    "                    y_pred_probs_train = y_pred_probs_train.numpy().flatten()\n",
    "                    auc_score_test = roc_auc_score(y_test.numpy(), y_pred_probs_test)\n",
    "                    auc_score_train = roc_auc_score(y_train.numpy(), y_pred_probs_train)\n",
    "\n",
    "                # Сравнение с текущим лучшим результатом\n",
    "                if auc_score_test > best_auc:\n",
    "                    best_auc = auc_score_test\n",
    "                    best_hidden_sizes = (hidden_size1, hidden_size2, hidden_size3, hidden_size4)\n",
    "                    best_num_epochs = num_epochs\n",
    "\n",
    "print(f'Лучший AUC: {best_auc:.4f}')\n",
    "print(f'Лучшие размеры скрытых слоев: {best_hidden_sizes}')\n",
    "print(f'Лучшее количество эпох: {best_num_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b0ee9095-97e1-4973-97d6-251980072d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший AUC: 0.8372\n",
      "Лучшие размеры скрытых слоев: (5, 5, 35, 125)\n",
      "Лучшее количество эпох: 950\n"
     ]
    }
   ],
   "source": [
    "print(f'Лучший AUC: {best_auc:.4f}')\n",
    "print(f'Лучшие размеры скрытых слоев: {best_hidden_sizes}')\n",
    "print(f'Лучшее количество эпох: {best_num_epochs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
